{"pages":[],"posts":[{"title":"AQS","text":"AQS简介是AbstractQueuedSynchronizer的简称，是一个用来构建锁和同步器的框架，比如ReentrantLock，Semaphore，ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。 AQS源码分析内部数据结构它维护了一个volatile int state（代表共享资源）和一个FIFO线程等待双端队列（多线程争用资源被阻塞时会进入此队列），并使用了两个指针head和tail用于标识队列的头部和尾部。 123456789101112131415161718192021222324252627282930313233343536373839/** * The synchronization state. */private volatile int state;/** * Returns the current value of synchronization state. * This operation has memory semantics of a {@code volatile} read. * @return current state value */protected final int getState() { return state;}/** * Sets the value of synchronization state. * This operation has memory semantics of a {@code volatile} write. * @param newState the new state value */protected final void setState(int newState) { state = newState;}/** * Atomically sets synchronization state to the given updated * value if the current state value equals the expected value. * This operation has memory semantics of a {@code volatile} read * and write. * * @param expect the expected value * @param update the new value * @return {@code true} if successful. False return indicates that the actual * value was not equal to the expected value. */protected final boolean compareAndSetState(int expect, int update) { // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update);} CLH队列并不是直接存储线程，而是存储拥有线程的Node节点 Node的结构： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061static final class Node { // 标记一个结点（对应的线程）在共享模式下等待 static final Node SHARED = new Node(); // 标记一个结点（对应的线程）在独占模式下等待 static final Node EXCLUSIVE = null; // waitStatus的值，表示该结点（对应的线程）已被取消 static final int CANCELLED = 1; // waitStatus的值，表示后继结点（对应的线程）需要被唤醒 static final int SIGNAL = -1; // waitStatus的值，表示该结点（对应的线程）在等待某一条件 static final int CONDITION = -2; /*waitStatus的值，表示有资源可用，新head结点需要继续唤醒后继结点（共享模式下，前继结点不仅会唤醒其后继结点，同时也可能会唤醒后继的后继结点。）*/ static final int PROPAGATE = -3; // 0:新结点入队时的默认状态 // 等待状态，取值范围，-3，-2，-1，0，1 volatile int waitStatus; volatile Node prev; // 前驱结点 volatile Node next; // 后继结点 volatile Thread thread; // 结点对应的线程 Node nextWaiter; // 等待队列里下一个等待条件的结点 // 判断共享模式的方法 final boolean isShared() { return nextWaiter == SHARED; } /** * Returns previous node, or throws NullPointerException if null. * Use when predecessor cannot be null. The null check could * be elided, but is present to help the VM. * * @return the predecessor of this node */ final Node predecessor() throws NullPointerException { Node p = prev; if (p == null) throw new NullPointerException(); else return p; } Node() { // Used to establish initial head or SHARED marker } Node(Thread thread, Node mode) { // Used by addWaiter this.nextWaiter = mode; this.thread = thread; } Node(Thread thread, int waitStatus) { // Used by Condition this.waitStatus = waitStatus; this.thread = thread; }} 资源共享模式资源有两种共享模式，或者说两种同步方式： 独占模式（Exclusive）：资源是独占的，一次只能一个线程获取。如ReentrantLock。 共享模式（Share）：同时可以被多个线程获取，具体的资源个数可以通过参数指定。如Semaphore/CountDownLatch。 不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。自定义同步器实现时主要实现以下几种方法： isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。 tryAcquire(int)：独占模式。尝试获取资源，成功则返回true，失败则返回false。 tryRelease(int)：独占模式。尝试释放资源，成功则返回true，失败则返回false。 tryAcquireShared(int)：共享模式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 tryReleaseShared(int)：共享模式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。 这些方法虽然都是protected方法，但是它们并没有在AQS具体实现，而是直接抛出异常，因为AQS只是一个框架，具体资源的获取/释放方式交由自定义同步器去实现 123protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException();} 这里没有定义成abstract的原因： 独占模式下只需要实现tryAcquire-tryRelease，而共享模式下只需要实现tryAcquireShared-tryReleaseShared。如果都定义成abstract，那么每个模式也要去实现另一模式下的接口。 （一般情况下，子类只需要根据需求实现其中一种模式，当然也有同时实现两种模式的同步类，如ReadWriteLock。） 核心部分的源码分析 获取资源（独占） 123456789101112131415161718/** * Acquires in exclusive mode, ignoring interrupts. Implemented * by invoking at least once {@link #tryAcquire}, * returning on success. Otherwise the thread is queued, possibly * repeatedly blocking and unblocking, invoking {@link * #tryAcquire} until success. This method can be used * to implement method {@link Lock#lock}. * * @param arg the acquire argument. This value is conveyed to * {@link #tryAcquire} but is otherwise uninterpreted and * can represent anything you like. */// arg是要获取的资源的个数，在独占模式下始终为1。public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();} 函数流程如下： 1）tryAcquire()尝试直接去获取资源，如果成功则直接返回（这里体现了非公平锁，每个线程获取锁时会尝试直接抢占加塞一次，而CLH队列中可能还有别的线程在等待）； 2）addWaiter()将该线程加入等待队列的尾部，并标记为独占模式； 3）acquireQueued()使线程阻塞在等待队列中获取资源，一直获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false； 4）如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166/** * Attempts to acquire in exclusive mode. This method should query * if the state of the object permits it to be acquired in the * exclusive mode, and if so to acquire it. * * &lt;p&gt;This method is always invoked by the thread performing * acquire. If this method reports failure, the acquire method * may queue the thread, if it is not already queued, until it is * signalled by a release from some other thread. This can be used * to implement method {@link Lock#tryLock()}. */// 尝试去获取独占资源。如果获取成功，则直接返回true，否则直接返回false。// 需自定义同步器去实现 tryLock()protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException();}/** * Creates and enqueues node for current thread and given mode. * * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared * @return the new node */// 将当前线程加入到等待队列的队尾，并返回当前线程所在的结点。private Node addWaiter(Node mode) { // 生成该线程对应的Node节点 Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure // 尝试快速方式直接放到队尾 Node pred = tail; if (pred != null) { node.prev = pred; // 使用CAS尝试，成功则返回 if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } // 如果等待队列为空或者上述CAS失败，通过自旋CAS插入（enq方法） enq(node); return node;}/** * Inserts node into queue, initializing if necessary. See picture above. * @param node the node to insert * @return node's predecessor */// 将node加入队尾private Node enq(final Node node) { // CAS自旋，直到成功加入队尾 for (;;) { Node t = tail; if (t == null) { // Must initialize // 队列为空，创建一个空的标志结点作为head结点，并将tail也指向它。 if (compareAndSetHead(new Node())) tail = head; } else { //正常流程，放入队尾 node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } }}/** * Acquires in exclusive uninterruptible mode for thread already in * queue. Used by condition wait methods as well as acquire. * * @param node the node * @param arg the acquire argument * @return {@code true} if interrupted while waiting *//** * 1. 结点进入队尾后，检查状态，找到安全休息点； * 2. 调用park()进入waiting状态，等待unpark()或interrupt()唤醒自己； * 3. 被唤醒后，看自己是否可以获取到资源。如果拿到，head指向当前结点，并返回从入队到获取到的整个过程中是否被中断过；如果没获取到，继续流程1。 */final boolean acquireQueued(final Node node, int arg) { // 标记是否成功拿到资源 boolean failed = true; try { // 标记等待过程中是否被中断过 boolean interrupted = false; // 自旋 for (;;) { // 获取前驱节点 final Node p = node.predecessor(); // 若前驱结点p是head，说明node是第二个结点，可以尝试去获取资源 if (p == head &amp;&amp; tryAcquire(arg)) { // 拿到资源后，将head指向该结点。 // 所以head所指的结点，就是当前获取到资源的那个结点或null。 setHead(node); // setHead中node.prev已置为null，此处再将head.next置为null，是为了方便GC回收以前的head结点。(意味着将之前拿完资源的结点出队) p.next = null; // help GC // 成功获取资源 failed = false; //返回等待过程中是否被中断过 return interrupted; } // 如果自己可以休息了，就进入waiting状态，直到被unpark() if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { // 如果等待过程中没有成功获取资源（如timeout，或者可中断的情况下被中断了），那么取消结点在队列中的等待。 if (failed) cancelAcquire(node); }}/** * Checks and updates status for a node that failed to acquire. * Returns true if thread should block. This is the main signal * control in all acquire loops. Requires that pred == node.prev. * * @param pred node's predecessor holding status * @param node the node * @return {@code true} if thread should block */private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { // 获取前驱节点状态 int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) { /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ // 如果前驱放弃了，就一直往前找，直到找到一个正常等待状态的node，排在它的后面。 do { node.prev = pred = pred.prev; } while (pred.waitStatus &gt; 0); pred.next = node; } else { /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ // 如果前驱正常，就把前驱的状态设置成SIGNAL。 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false;}/** * Convenience method to park and then check if interrupted * * @return {@code true} if interrupted */private final boolean parkAndCheckInterrupt() { // 调用park()使线程进入waiting状态 LockSupport.park(this); // 如果被唤醒，查看自己是不是被中断的。 return Thread.interrupted();} 注意： 队列的尾部插入新的Node节点：由于AQS中会存在多个线程同时争夺资源的情况，因此肯定会出现多个线程同时插入节点的操作，所以在这里是通过CAS自旋的方式保证了操作的线程安全性。（addWaiter()和enq()） park()会让当前线程进入waiting状态。在此状态下，有两种情况可以唤醒该线程：1）被unpark()；2）被interrupt()。 LockSupport类是Java 6 引入的，提供了基本的线程同步原语。LockSupport实际上是调用了Unsafe类里的函数，归结到Unsafe里，只有两个函数： park(boolean isAbsolute, long time)：阻塞当前线程 unpark(Thread jthread)：使给定的线程停止阻塞 所以结点进入等待队列后，是调用park使它进入阻塞状态的。只有头结点的线程是处于活跃状态的。 释放资源（独占） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * Releases in exclusive mode. Implemented by unblocking one or * more threads if {@link #tryRelease} returns true. * This method can be used to implement method {@link Lock#unlock}. * * @param arg the release argument. This value is conveyed to * {@link #tryRelease} but is otherwise uninterpreted and * can represent anything you like. * @return the value returned from {@link #tryRelease} */// 释放指定量的资源，如果彻底释放了（即state=0）,它会唤醒等待队列里的其他线程来获取资源。public final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) // 唤醒等待队列里的下一个线程 unparkSuccessor(h); return true; } return false;}/** * Attempts to set the state to reflect a release in exclusive * mode. * * &lt;p&gt;This method is always invoked by the thread performing release. * */// 需要独占模式的自定义同步器去实现protected boolean tryRelease(int arg) { throw new UnsupportedOperationException();}/** * Wakes up node's successor, if one exists. * * @param node the node */private void unparkSuccessor(Node node) { /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; // 置零当前线程所在的节点状态，允许失败 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ // 找到下一个需要唤醒的节点 Node s = node.next; // 如果这个后继结点为空或者状态大于0，即这个结点已被取消 if (s == null || s.waitStatus &gt; 0) { s = null; // 将等待队列中所有还有用的结点向前移动（从后向前找） for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; } if (s != null) // 唤醒 LockSupport.unpark(s.thread);} 获取资源（共享） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112/** * Acquires in shared mode, ignoring interrupts. Implemented by * first invoking at least once {@link #tryAcquireShared}, * returning on success. Otherwise the thread is queued, possibly * repeatedly blocking and unblocking, invoking {@link * #tryAcquireShared} until success. * * @param arg the acquire argument. This value is conveyed to * {@link #tryAcquireShared} but is otherwise uninterpreted * and can represent anything you like. */// 获取指定量的资源，获取成功则直接返回；获取失败则进入等待队列，直到获取到资源为止，整个过程忽略中断。public final void acquireShared(int arg) { if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);}/** * Attempts to acquire in shared mode. This method should query if * the state of the object permits it to be acquired in the shared * mode, and if so to acquire it. * * &lt;p&gt;This method is always invoked by the thread performing * acquire. If this method reports failure, the acquire method * may queue the thread, if it is not already queued, until it is * signalled by a release from some other thread. * * &lt;p&gt;The default implementation throws {@link * UnsupportedOperationException}. */// 返回值：负值代表获取失败；0代表获取成功，但没有剩余资源；正数表示获取成功，还有剩余资源，其他线程还可以去获取。protected int tryAcquireShared(int arg) { throw new UnsupportedOperationException();}/** * Acquires in shared uninterruptible mode. * @param arg the acquire argument */// 将当前线程加入等待队列尾部休息，直到其他线程释放资源唤醒自己，成功拿到相应量的资源后才返回。private void doAcquireShared(int arg) { // 加入队列尾部 final Node node = addWaiter(Node.SHARED); // 标记是否成功 boolean failed = true; try { // 标记等待过程中是否被中断过 boolean interrupted = false; for (;;) { // 获取前驱节点 final Node p = node.predecessor(); // 如果到head的下一个，因为head是拿到资源的线程，此时node被唤醒，很可能是head用完资源来唤醒自己 if (p == head) { // 尝试获取资源 int r = tryAcquireShared(arg); if (r &gt;= 0) { setHeadAndPropagate(node, r); p.next = null; // help GC // 如果等待过程中被打断过，此时将中断补上。 if (interrupted) selfInterrupt(); failed = false; return; } } // 判断状态，寻找安全点，进入waiting状态，等着被unpark()或interrupt() if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); }}/** * Sets head of queue, and checks if successor may be waiting * in shared mode, if so propagating if either propagate &gt; 0 or * PROPAGATE status was set. * * @param node the node * @param propagate the return value from a tryAcquireShared */private void setHeadAndPropagate(Node node, int propagate) { Node h = head; // Record old head for check below setHead(node); /* * Try to signal next queued node if: * Propagation was indicated by caller, * or was recorded (as h.waitStatus either before * or after setHead) by a previous operation * (note: this uses sign-check of waitStatus because * PROPAGATE status may transition to SIGNAL.) * and * The next node is waiting in shared mode, * or we don't know, because it appears null * * The conservatism in both of these checks may cause * unnecessary wake-ups, but only when there are multiple * racing acquires/releases, so most need signals now or soon * anyway. */ // 如果还有剩余量，继续唤醒下一个邻居线程 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) { Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); }} 流程： 1）tryAcquireShared()尝试获取资源，成功则直接返回； 2）失败则通过doAcquireShared()进入等待队列park()，直到被unpark()/interrupt()并成功获取到资源才返回。整个等待过程也是忽略中断的。 释放资源（共享） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * Releases in shared mode. Implemented by unblocking one or more * threads if {@link #tryReleaseShared} returns true. * * @param arg the release argument. This value is conveyed to * {@link #tryReleaseShared} but is otherwise uninterpreted * and can represent anything you like. * @return the value returned from {@link #tryReleaseShared} */// 释放指定量的资源，如果成功释放且允许唤醒等待线程，它会唤醒等待队列里的其他线程来获取资源。public final boolean releaseShared(int arg) { // 尝试释放资源 if (tryReleaseShared(arg)) { // 唤醒后继节点 doReleaseShared(); return true; } return false;}/** * Release action for shared mode -- signals successor and ensures * propagation. (Note: For exclusive mode, release just amounts * to calling unparkSuccessor of head if it needs signal.) */private void doReleaseShared() { /* * Ensure that a release propagates, even if there are other * in-progress acquires/releases. This proceeds in the usual * way of trying to unparkSuccessor of head if it needs * signal. But if it does not, status is set to PROPAGATE to * ensure that upon release, propagation continues. * Additionally, we must loop in case a new node is added * while we are doing this. Also, unlike other uses of * unparkSuccessor, we need to know if CAS to reset status * fails, if so rechecking. */ for (;;) { Node h = head; if (h != null &amp;&amp; h != tail) { int ws = h.waitStatus; if (ws == Node.SIGNAL) { if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases // 唤醒后继节点 unparkSuccessor(h); } else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS } if (h == head) // loop if head changed break; }} 其他 获取资源的方法除了acquire外，还有以下三个： acquireInterruptibly：申请可中断的资源（独占模式） acquireShared：申请共享模式的资源 acquireSharedInterruptibly：申请可中断的资源（共享模式）","link":"/2020/07/16/AQS/"},{"title":"CAS","text":"","link":"/2020/07/14/CAS/"},{"title":"CopyOnWrite","text":"CopyOnWrite容器简介可以理解为写时复制的容器，当向容器中添加元素时，不是直接往容器中添加，而是将当前容器进行copy，复制出一个新的容器，然后向新容器中添加元素，最后将原容器的引用指向新容器。 好处：在并发的场景下对容器进行”读操作”而不需要”加锁”，从而达到读写分离的目的。 从JDK 1.5 开始Java并发包里提供了两个使用CopyOnWrite机制实现的并发容器，分别是CopyOnWriteArrayList和CopyOnWriteArraySet。 CopyOnWriteArrayList优缺点分析优点：适用于读多写少的场景。在Java中遍历线程非安全的List时（如：ArrayList和 LinkedList），若中途有其他线程对List容器进行修改，那么会抛出ConcurrentModificationException异常。CopyOnWriteArrayList由于其“读写分离”，遍历和修改操作分别作用在不同的List容器，所以在使用迭代器遍历的时候，则不会抛出异常。 缺点：1）每次执行写操作都会将原容器拷贝一份，数据量大的时候，内存会存在较大的压力，可能会引起频繁Young GC和Full GC；2）只能保证最终数据一致性，不能保证实时一致性。 源码分析12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * Appends the specified element to the end of this list. * * @param e element to be appended to this list * @return {@code true} (as specified by {@link Collection#add}) */public boolean add(E e) { final ReentrantLock lock = this.lock; lock.lock(); try { Object[] elements = getArray(); int len = elements.length; // 拷贝原容器，长度加一 Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; // 将原容器引用指向新副本 setArray(newElements); return true; } finally { lock.unlock(); }}/** * Removes the element at the specified position in this list. * Shifts any subsequent elements to the left (subtracts one from their * indices). Returns the element that was removed from the list. * * @throws IndexOutOfBoundsException {@inheritDoc} */public E remove(int index) { final ReentrantLock lock = this.lock; lock.lock(); try { Object[] elements = getArray(); int len = elements.length; E oldValue = get(elements, index); int numMoved = len - index - 1; // 如果要删除的是列表末端数据，拷贝前len-1个数据到新副本上，再切换引用 if (numMoved == 0) setArray(Arrays.copyOf(elements, len - 1)); else { // 否则，将除要删除元素之外的其他元素拷贝到新副本中，并切换引用 Object[] newElements = new Object[len - 1]; System.arraycopy(elements, 0, newElements, 0, index); System.arraycopy(elements, index + 1, newElements, index, numMoved); setArray(newElements); } return oldValue; } finally { lock.unlock(); }}public E get(int index) { return get(getArray(), index);}","link":"/2020/07/17/CopyOnWrite/"},{"title":"DistributedTransaction","text":"分布式事务事务简介 事务是用来保证一组数据操作的完整性和一致性 事务必须满足ACID的四大特性（待补全） 事务具有四种隔离级别（待补全） 事务具有七种传播行为（待补全） 什么是分布式事务分布式事务就是将多个节点的事务看成一个整体处理。 分布式事务由事务参与者、资源服务器、事务管理器等组成，常见例子有，支付、下订单等。 实现思路两段式事务 请求阶段：协调者向参与者询问是否可以进行事务提交操作，然后开始等待参与者的响应。 提交阶段：在该阶段，协调者将基于第一个阶段的投票结果进行决策：提交或取消。当且仅当所有的参与者同意提交，事务协调者才通知所有的参与者提交事务，否则协调者将通知所有的参与者回滚事务。 缺点：1）当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态；2）当协调者出错，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作；3）假如在第二阶段中，假如协调者发出commit消息后宕机，接收到这条消息的参与者宕机，此时则无法判断事务状态，无法确定是否已被提交； 三段式事务事务询问 -&gt; 执行事务预提交 -&gt; 进行事务提交或者事务回滚 降低了参与者的阻塞范围，但引入了新问题：在参与者接收到precommit后，网络出现问题，参与者和协调者无法通行，在这种情况下，参与者依然会执行事务的提交。 基于XA的分布式事务 缺点：1）性能较差；2）很多nosql不支持XA协议； 基于消息的最终一致性方案 缺点：属于强一致性事务，会存在资源浪费 TCC编程式补偿性事务 TCC事务是柔性事务，在try阶段要对资源做预留，在confirm或cancel阶段释放资源，与基于消息事务对比，TCC的时效性更好。 TCC模型是把锁的粒度完全交给业务处理，它分为三个阶段： Try阶段主要是对业务系统做检测及资源预留； 如果try阶段所有业务资源都预留成功，则执行confirm，否则执行cancel； confirm：不做任务业务检查，仅使用预留的资源执行业务操作，失败会重试； cancel：取消执行业务操作，释放预留的资源，失败会重试； 举例以简单的电商系统为例，小明在淘宝上花100元买了一本书，获赠10个积分，产生如下操作： 订单系统创建商品订单； 支付系统接受小明的支付； 库存系统扣减产品库存； 会员系统给小明账户增加会员积分； 这几个动作需要作为一个事务执行，要同时成功或者同时撤销。如果采用TCC事务模式，那么各个系统需要改造为如下状态： 1）订单系统 try：创建一个订单，状态显示为“待支付”； confirm：更新订单的状态为“已完成”； cancel：更新订单的状态为“已取消”；2）支付系统 try：假设小明账户中有1000元，冻结小明账户中的100元，此时小明看到的余额依然是1000元； confirm：将账户余额变为900元，并清除冻结记录； concel：清除冻结记录；3）库存系统 try：假设库存中还生10本书，冻结其中的一本书，现实库存依然有10本书； confirm：将剩余库存更新为9本书，并清除冻结记录； cancel：清除冻结记录；4）会员系统 try：假设小明原因积分为3000，给小明账户预增加10积分，账户显示的积分依然是3000分； confirm：将账户积分更新为3010，并清除预增加记录； cancel：清除预增加记录； 缺点：TCC 事务模型对业务方侵入较大，需要业务方把功能的实现上由一个接口拆分为三个，开发成本较高。 同时 TCC 事务为了解决异步网络中的通信失败或超时带来的异常情况，要求业务方在设计实现上要遵循三个策略： 允许空回滚：原因是异常发生在阶段 1 时，部分参与方没有收到 try 请求从而触发整个事务的 cancel 操作，try 失败或者没有执行 try 操作的参与方收到 cancel 请求时，要进行空回滚操作； 保持幂等性：原因是异常发生在阶段 2 时，比如网络超时，则会重复调用参与方的 confirm/cancel 方法，因此需要这两个方法实现上保证幂等性； 防止资源悬挂：原因网络异常导致两个阶段无法保证严格的顺序执行，出现参与方侧 try 请求比 cancel 请求更晚到达的情况，cancel 会执行空回滚而确保事务的正确性，但是此时 try 方法也不可以再被执行； 分布式事务框架 全局事务框架GTS 蚂蚁金服分布式事务DTX 开源TCC框架TCC-Transaction（https://github.com/changmingxie/tcc-transaction） 开源TCC框架Byte-（https://github.com/liuyangming/ByteTCC） TCC-Transaction分析 仓库：https://github.com/changmingxie/tcc-transaction 使用方法 在需要提供分布式事务支持的接口方法上添加 @Compensable； 在对应的接口实现方法上也添加 @Compensable，并添加注解参数 confirmMethod, cancelMethod 和 transactionContextEditor； 实现对应的 confirmMethod 和 cancelMethod（必须和 try 方法在同一个类中）； 注意： 在分布式事务框架中，不要轻易在业务层捕获所有异常，只有在抛出异常的情况下，分布式事务框架才知道该业务是执行失败的，继而执行cancelMethod； 使用 TCC-Transaction 时，confirm 和 cancel 的幂等性问题需要人为代码保证； TCC 的数据库应该和业务数据库分开，以保证分布式事务的正常进行； 源码分析 tcc的事务并不是数据库的事务，而是应用层的事务，Transaction如下： 12345678910111213141516171819202122public class Transaction implements Serializable { private static final long serialVersionUID = 7291423944314337931L; // 全局事务id，用来保证事务唯一性 private TransactionXid xid; // 事务的状态 private TransactionStatus status; // 事务类型，ROOT是主事务，BRANCH是分支事务 private TransactionType transactionType; // 事务重试次数 private volatile int retriedCount = 0; // 事务创建时间 private Date createTime = new Date(); // 事务最后一次更新的时间 private Date lastUpdateTime = new Date(); // 事务的版本号 private long version = 1; // 事务的参与者 private List&lt;Participant&gt; participants = new ArrayList&lt;Participant&gt;(); // 附加参数 private Map&lt;String, Object&gt; attachments = new ConcurrentHashMap&lt;String, Object&gt;(); ...} CompensableTransactionAspect是一个AOP切面类，@Pointcut 将 @Compensable 注解标记为切入点，其签名为compensableService()。@Around 表示在compensableService()之前和之后调用 interceptCompensableMethod()。 123456789101112131415@Aspectpublic abstract class CompensableTransactionAspect { private CompensableTransactionInterceptor compensableTransactionInterceptor; public void setCompensableTransactionInterceptor(CompensableTransactionInterceptor compensableTransactionInterceptor) { this.compensableTransactionInterceptor = compensableTransactionInterceptor; } @Pointcut(\"@annotation(org.mengyun.tcctransaction.api.Compensable)\") public void compensableService() { } @Around(\"compensableService()\") public Object interceptCompensableMethod(ProceedingJoinPoint pjp) throws Throwable { return compensableTransactionInterceptor.interceptCompensableMethod(pjp); } public abstract int getOrder();} CompensableTransactionInterceptor是事务拦截器，具有以下作用： 将事务区分为ROOT事务和PROVIDER分支事务； 不断地修改数据库内的状态（初始化事务、修改事务状态）； 修改和清除事务管理区中的事务队列； 并没有执行目标对象方法，pjp.proceed() 其实是交给了下一个拦截器 ResourceCoordinatorInterceptor； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138public class CompensableMethodContext { ProceedingJoinPoint pjp = null; Method method = null; // 解析得到的Compensable注解 Compensable compensable = null; Propagation propagation = null; // 保存了全局事务id和事务状态，在调用事务参与者Participant的confirm或cancel方法时会传递过去。 TransactionContext transactionContext = null; public CompensableMethodContext(ProceedingJoinPoint pjp) { this.pjp = pjp; this.method = getCompensableMethod(); this.compensable = method.getAnnotation(Compensable.class); this.propagation = compensable.propagation(); this.transactionContext = FactoryBuilder.factoryOf(compensable.transactionContextEditor()).getInstance().get(pjp.getTarget(), method, pjp.getArgs()); } ...}public class CompensableTransactionInterceptor { public Object interceptCompensableMethod(ProceedingJoinPoint pjp) throws Throwable { // 通过pjp解析各种属性，组成CompansableMethodContext对象 CompensableMethodContext compensableMethodContext = new CompensableMethodContext(pjp); // 是否有存在的事务队列（从ThreadLocal获取transactions来判断当前线程是否已经有事务） boolean isTransactionActive = transactionManager.isTransactionActive(); if (!TransactionUtils.isLegalTransactionContext(isTransactionActive, compensableMethodContext)) { throw new SystemException(\"no active compensable transaction while propagation is mandatory for method \" + compensableMethodContext.getMethod().getName()); } // 获取并判断当前事务的角色（ROOT表示主事务，PROVIDER表示分支事务或事务参与者），并根据其角色调用不同的方法来处理。 switch (compensableMethodContext.getMethodRole(isTransactionActive)) { // 处理主事务切面 case ROOT: return rootMethodProceed(compensableMethodContext); // 处理PROVIDER事务切面 case PROVIDER: return providerMethodProceed(compensableMethodContext); default: return pjp.proceed(); } } /** * 1. 开启全局事务 * 2. 持久化全局事务 * 3. 注册全局事务 * 4. 判断应该是confirm还是cancel * 5. 清除事务 * * @param compensableMethodContext * @return * @throws Throwable */ private Object rootMethodProceed(CompensableMethodContext compensableMethodContext) throws Throwable { Object returnValue = null; Transaction transaction = null; boolean asyncConfirm = compensableMethodContext.getAnnotation().asyncConfirm(); boolean asyncCancel = compensableMethodContext.getAnnotation().asyncCancel(); Set&lt;Class&lt;? extends Exception&gt;&gt; allDelayCancelExceptions = new HashSet&lt;Class&lt;? extends Exception&gt;&gt;(); allDelayCancelExceptions.addAll(this.delayCancelExceptions); allDelayCancelExceptions.addAll(Arrays.asList(compensableMethodContext.getAnnotation().delayCancelExceptions())); try { /** * 开启一个全新的事务 * 1. 持久化事务形态 -&gt; 全局事务编号 * 2. 注册一个事务【ThreadLocal】 */ transaction = transactionManager.begin(compensableMethodContext.getUniqueIdentity()); try { // 执行后续方法 returnValue = compensableMethodContext.proceed(); } catch (Throwable tryingException) { if (!isDelayCancelException(tryingException, allDelayCancelExceptions)) { logger.warn(String.format(\"compensable transaction trying failed. transaction content:%s\", JSON.toJSONString(transaction)), tryingException); // 回滚事务 transactionManager.rollback(asyncCancel); } throw tryingException; } // 提交事务 transactionManager.commit(asyncConfirm); } finally { // 清除队列中的事务 transactionManager.cleanAfterCompletion(transaction); } return returnValue; } private Object providerMethodProceed(CompensableMethodContext compensableMethodContext) throws Throwable { Transaction transaction = null; boolean asyncConfirm = compensableMethodContext.getAnnotation().asyncConfirm(); boolean asyncCancel = compensableMethodContext.getAnnotation().asyncCancel(); try { switch (TransactionStatus.valueOf(compensableMethodContext.getTransactionContext().getStatus())) { case TRYING: // 初始化一份事务参与者的数据进入到当前服务中，并向事务管理器注册事务 transaction = transactionManager.propagationNewBegin(compensableMethodContext.getTransactionContext()); return compensableMethodContext.proceed(); case CONFIRMING: // 修改状态 try { transaction = transactionManager.propagationExistBegin(compensableMethodContext.getTransactionContext()); // 修改事务状态为CONFIRMING，并持久化更新，提交事务 transactionManager.commit(asyncConfirm); } catch (NoExistedTransactionException excepton) { //the transaction has been commit,ignore it. } break; case CANCELLING: try { transaction = transactionManager.propagationExistBegin(compensableMethodContext.getTransactionContext()); // 修改事务状态为 CANCELLING，并持久化更新，回滚事务 transactionManager.rollback(asyncCancel); } catch (NoExistedTransactionException exception) { //the transaction has been rollback,ignore it. } break; } } finally { // 清除事务 transactionManager.cleanAfterCompletion(transaction); } Method method = compensableMethodContext.getMethod(); return ReflectionUtils.getNullValue(method.getReturnType()); } private boolean isDelayCancelException(Throwable throwable, Set&lt;Class&lt;? extends Exception&gt;&gt; delayCancelExceptions) { if (delayCancelExceptions != null) { for (Class delayCancelException : delayCancelExceptions) { Throwable rootCause = ExceptionUtils.getRootCause(throwable); if (delayCancelException.isAssignableFrom(throwable.getClass()) || (rootCause != null &amp;&amp; delayCancelException.isAssignableFrom(rootCause.getClass()))) { return true; } } } return false; }} TransactionManager 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118public class TransactionManager { private TransactionRepository transactionRepository; private static final ThreadLocal&lt;Deque&lt;Transaction&gt;&gt; CURRENT = new ThreadLocal&lt;Deque&lt;Transaction&gt;&gt;(); private ExecutorService executorService; ... // 开启事务，持久化到repository，注册到ThreadLocal public Transaction begin(Object uniqueIdentify) { Transaction transaction = new Transaction(uniqueIdentify,TransactionType.ROOT); transactionRepository.create(transaction); registerTransaction(transaction); return transaction; } // 从主事务的上下文创建分支事务，xid不变，事务类型变化 public Transaction propagationNewBegin(TransactionContext transactionContext) { Transaction transaction = new Transaction(transactionContext); transactionRepository.create(transaction); registerTransaction(transaction); return transaction; } // 从事务上下文同步事务状态到ThreadLocal public Transaction propagationExistBegin(TransactionContext transactionContext) throws NoExistedTransactionException { Transaction transaction = transactionRepository.findByXid(transactionContext.getXid()); if (transaction != null) { transaction.changeStatus(TransactionStatus.valueOf(transactionContext.getStatus())); registerTransaction(transaction); return transaction; } else { throw new NoExistedTransactionException(); } } public void commit(boolean asyncCommit) { // 从ThreadLocal获取当前事务 final Transaction transaction = getCurrentTransaction(); transaction.changeStatus(TransactionStatus.CONFIRMING); // 数据库更新transaction transactionRepository.update(transaction); if (asyncCommit) { try { Long statTime = System.currentTimeMillis(); // 通过线程池异步执行事务提交 executorService.submit(new Runnable() { @Override public void run() { commitTransaction(transaction); } }); logger.debug(\"async submit cost time:\" + (System.currentTimeMillis() - statTime)); } catch (Throwable commitException) { logger.warn(\"compensable transaction async submit confirm failed, recovery job will try to confirm later.\", commitException); throw new ConfirmingException(commitException); } } else { // 同步执行事务提交 commitTransaction(transaction); } } private void commitTransaction(Transaction transaction) { try { // 调用事务参与者的commit方法 transaction.commit(); // 事务结束，在数据库删除当前事务，如果commit异常，不会删除数据库内事务记录，为了重试补偿 transactionRepository.delete(transaction); } catch (Throwable commitException) { logger.warn(\"compensable transaction confirm failed, recovery job will try to confirm later.\", commitException); throw new ConfirmingException(commitException); } } public void rollback(boolean asyncRollback) { final Transaction transaction = getCurrentTransaction(); transaction.changeStatus(TransactionStatus.CANCELLING); transactionRepository.update(transaction); if (asyncRollback) { try { executorService.submit(new Runnable() { @Override public void run() { rollbackTransaction(transaction); } }); } catch (Throwable rollbackException) { logger.warn(\"compensable transaction async rollback failed, recovery job will try to rollback later.\", rollbackException); throw new CancellingException(rollbackException); } } else { rollbackTransaction(transaction); } } // 把transaction注册到ThreadLocal对象中 private void registerTransaction(Transaction transaction) { if (CURRENT.get() == null) { CURRENT.set(new LinkedList&lt;Transaction&gt;()); } CURRENT.get().push(transaction); } // 事务结束，从栈中弹出结束的事务 public void cleanAfterCompletion(Transaction transaction) { if (isTransactionActive() &amp;&amp; transaction != null) { Transaction currentTransaction = getCurrentTransaction(); if (currentTransaction == transaction) { CURRENT.get().pop(); if (CURRENT.get().size() == 0) { CURRENT.remove(); } } else { throw new SystemException(\"Illegal transaction when clean after completion\"); } } } ...} ResourceCoordinatorAspect：主要是为了设置事务的参与者 12345678910111213141516@Aspectpublic abstract class ResourceCoordinatorAspect { private ResourceCoordinatorInterceptor resourceCoordinatorInterceptor; @Pointcut(\"@annotation(org.mengyun.tcctransaction.api.Compensable)\") public void transactionContextCall() { } @Around(\"transactionContextCall()\") public Object interceptTransactionContextMethod(ProceedingJoinPoint pjp) throws Throwable { return resourceCoordinatorInterceptor.interceptTransactionContextMethod(pjp); } public void setResourceCoordinatorInterceptor(ResourceCoordinatorInterceptor resourceCoordinatorInterceptor) { this.resourceCoordinatorInterceptor = resourceCoordinatorInterceptor; } public abstract int getOrder();} ResourceCoordinatorInterceptor：主要处理 try 阶段的事情，在 try 阶段，就将所有的“资源”封装完成并交给事务管理器。然后事务管理器修改数据库状态。 “资源”指“事务资源”，即事务的参与者：confirm上下文，cancel上下文，分支事务信息。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class ResourceCoordinatorInterceptor { private TransactionManager transactionManager; public void setTransactionManager(TransactionManager transactionManager) { this.transactionManager = transactionManager; } public Object interceptTransactionContextMethod(ProceedingJoinPoint pjp) throws Throwable { // 获取当前事务 Transaction transaction = transactionManager.getCurrentTransaction(); if (transaction != null) { switch (transaction.getStatus()) { // 只需要在trying时，获取到参与者信息，并设置到transaction中 case TRYING: enlistParticipant(pjp); break; case CONFIRMING: break; case CANCELLING: break; } } // 执行目标方法 return pjp.proceed(pjp.getArgs()); } private void enlistParticipant(ProceedingJoinPoint pjp) throws IllegalAccessException, InstantiationException { // 获取@Compensable注解信息 Method method = CompensableMethodUtils.getCompensableMethod(pjp); if (method == null) { throw new RuntimeException(String.format(\"join point not found method, point is : %s\", pjp.getSignature().getName())); } Compensable compensable = method.getAnnotation(Compensable.class); String confirmMethodName = compensable.confirmMethod(); String cancelMethodName = compensable.cancelMethod(); Transaction transaction = transactionManager.getCurrentTransaction(); TransactionXid xid = new TransactionXid(transaction.getXid().getGlobalTransactionId()); if (FactoryBuilder.factoryOf(compensable.transactionContextEditor()).getInstance().get(pjp.getTarget(), method, pjp.getArgs()) == null) { FactoryBuilder.factoryOf(compensable.transactionContextEditor()).getInstance().set(new TransactionContext(xid, TransactionStatus.TRYING.getId()), pjp.getTarget(), ((MethodSignature) pjp.getSignature()).getMethod(), pjp.getArgs()); } Class targetClass = ReflectionUtils.getDeclaringType(pjp.getTarget().getClass(), method.getName(), method.getParameterTypes()); InvocationContext confirmInvocation = new InvocationContext(targetClass, confirmMethodName, method.getParameterTypes(), pjp.getArgs()); InvocationContext cancelInvocation = new InvocationContext(targetClass, cancelMethodName, method.getParameterTypes(), pjp.getArgs()); Participant participant = new Participant( xid, confirmInvocation, cancelInvocation, compensable.transactionContextEditor()); transactionManager.enlistParticipant(participant); }} 此时经过两个拦截器后，才调用到目标对象方法，即对应try逻辑的被切方法。","link":"/2020/07/26/DistributedTransaction/"},{"title":"HashMap","text":"常见相关实现类总结1）HashMap： 遍历顺序不确定； 最多只允许一条记录的键为null，允许多条记录的值为null； 非线程安全，若需保证线程安全，可以用Collections的synchronizedMap()，或者ConcurrentHashMap； 2）Hashtable： 线程安全，因为方法都用synchronized修饰，并发性不如ConcurrentHashMap； 3）LinkedHashMap 是HashMap的一个子类，保存了记录的插入顺序； 4）TreeMap 实现SortedMap接口，默认是按照键值的升序排序，也可以指定排序的比较器； 在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出异常java.lang.ClassCastException； 源码分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final int hash; //用来定位数组索引位置 final K key; V value; Node&lt;K,V&gt; next; //链表的下一个node Node(int hash, K key, V value, Node&lt;K,V&gt; next) { ... } public final K getKey(){ ... } public final V getValue() { ... } public final String toString() { ... } public final int hashCode() { ... } public final V setValue(V newValue) { ... } public final boolean equals(Object o) { ... }}/** * Returns a power of two size for the given target capacity. */// 找到大于等于cap的2的幂的最小值static final int tableSizeFor(int cap) { int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;}// 扰动函数// 好处1 让高位数据与低位数据进行异或，加大低位信息的随机性，变相的让高位数据参与到计算中// 好处2 增加hash的复杂度：覆写hashcode()时，可能会写出分布性不佳的方法，进而导致hash的冲突率比较高，此时通过移位和异或运算，可以让hash变得更加复杂，进而影响hash的分布性。// 以上是为什么hashmap不直接使用键对象原始hash的原因了static final int hash(Object key) { int h; // ^ ：按位异或 // &gt;&gt;&gt;:无符号右移，忽略符号位，空位都以0补齐 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);}public V put(K key, V value) { return putVal(hash(key), key, value, false, true);}/** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don't change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 初始化桶数组 table，table 被延迟到插入新数据时再进行初始化 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 如果桶中不包含键值对节点引用，则将新键值对节点的引用存入桶中即可 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node&lt;K,V&gt; e; K k; // 节点key存在，直接覆盖value if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 如果桶中的引用类型为 TreeNode，则调用红黑树的插入方法 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else { // 对链表进行遍历，并统计链表长度 for (int binCount = 0; ; ++binCount) { // 链表中不包含要插入的键值对节点时，则将该节点接在链表的最后 if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); // 如果链表长度大于或等于树化阈值，则进行树化操作 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } // key已经存在直接覆盖value if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } // 判断要插入的键值对是否存在 HashMap 中 if (e != null) { // existing mapping for key V oldValue = e.value; // onlyIfAbsent 表示是否仅在 oldValue 为 null 的情况下更新键值对的值 if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; // 键值对数量超过阈值时，进行扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;}/** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */final Node&lt;K,V&gt;[] resize() { Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; // 如果 table 不为空，表明已经初始化过了 if (oldCap &gt; 0) { // 当 table 容量超过容量最大值，则不再扩容 if (oldCap &gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } // 按旧容量和阈值的2倍计算新容量和阈值的大小 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold } // 初始化时，将threshold赋值给newCap，HashMap使用threshold变量暂时保存 initialCapacity的值 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; // 调用无参构造方法时，桶数组容量为默认容量，阈值为默认容量与默认负载因子乘积 else { // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } // newThr 为 0 时，按阈值计算公式进行计算 if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; // 创建新的桶数组，桶数组的初始化也是在这里完成的 @SuppressWarnings({\"rawtypes\",\"unchecked\"}) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 如果旧的桶数组不为空，则遍历桶数组，并将键值对映射到新的桶数组中 if (oldTab != null) { for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; // 重新映射时，需要对红黑树进行拆分 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else { // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; // 遍历链表，并将链表节点按原顺序进行分组 do { next = e.next; // 原索引 if ((e.hash &amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } // 原索引+oldCap else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); // 原索引放到bucket里 if (loTail != null) { loTail.next = null; newTab[j] = loHead; } // 原索引+oldCap放到bucket里 if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab;} 流程总结put(K,V)插入操作的入口方法是 put(K,V)，但核心逻辑在V putVal(int, K, V, boolean, boolean) 方法中。putVal()主要流程如下： ①.判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容； ②.根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③； ③.判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals； ④.判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤； ⑤.遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可； ⑥.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。 思考 为什么哈希桶数组table的长度length大小必须为2的n次方？ 相对来说素数导致冲突的概率要小于合数，例如，Hashtable初始化桶大小为11（Hashtable扩容后不能保证还是素数） HashMap采用这种非常规设计，主要是为了在取模和扩容时做优化，同时为了减少冲突，HashMap定位哈希桶索引位置时，也加入了高位参与运算的过程。 resize() 1.8相对于1.7做了什么优化？ 在jdk1.8中不需要像jdk1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”。","link":"/2020/07/18/HashMap/"},{"title":"Dubbo","text":"Dubbo相关的知识及常见问题：） 各种知识点总结常见面试题 Dubbo中的负载均衡算法及其特点 1）RandomLoadBalance：随机负载均衡，是Dubbo的默认负载均衡策略。 按照权重分配随机概率，在Dubbo中可以对 Provider设置权重。比如机器性能好的，可以设置大一点的权重，性能差的，可以设置小一点的权重。如果没有在Dubbo Admin中对服务 Provider 设置权重，那么所有的 Invoker 的权重就是一样的，默认是100。 2）RoundRobinLoadBalance：轮询负载均衡，依次的调用所有的Provider。 和随机负载均衡策略一样，轮询负载均衡策略也有权重的概念。轮询负载均衡算法可以让RPC调用严格按照我们设置的比例来分配。但是轮询负载均衡算法也有不足的地方，存在慢的Provider累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上，导致整个系统变慢。 3）LeastActiveLoadBalance：最少活跃调用数，相同活跃数的随机。活跃数指调用前后计数差。使慢的 Provider 收到更少请求，因为越慢的 Provider 的调用前后计数差会越大。 比如：每个服务维护一个活跃数计数器。当A机器开始处理请求，该计数器加1，此时A还未处理完成。若处理完毕则计数器减1。而B机器接受到请求后很快处理完毕。那么A,B的活跃数分别是1，0。当又产生了一个新的请求，则选择B机器去执行(B活跃数最小)，这样使慢的机器A收到少的请求。4）ConsistentHashLoadBalance：一致性Hash算法。相同参数的请求总是落在同一Provider。当某一台 Provider 崩溃时，原本发往该 Provider 的请求，基于虚拟节点，平摊到其它 Provider，不会引起剧烈变动。 一致性Hash算法可以和缓存机制配合起来使用。比如有一个服务getUserInfo(String userId)。设置了Hash算法后，相同的userId的调用，都会发送到同一个 Provider。这个 Provider 上可以把用户数据在内存中进行缓存，减少访问数据库或分布式缓存的次数。如果业务上允许这部分数据有一段时间的不一致，可以考虑这种做法。减少对数据库，缓存等中间件的依赖和访问次数，同时减少了网络IO操作，提高系统性能。 和Dubbo其他的配置类似，多个配置是有覆盖关系的： 方法级优先，接口级次之，全局配置再次之； 如果级别一样，则消费方优先，提供方次之； 1、dubbo中”读接口”和”写接口”有什么区别? 2、谈谈dubbo中的负载均衡算法及特点？ 3、最小活跃数算法中是如何统计这个活跃数的？ 4、简单谈谈你对一致性哈希算法的认识？ 5、服务发布过程中做了哪些事？ 6、dubbo都有哪些协议,他们之间有什么特点,缺省值是什么？ 7、什么是本地暴露和远程暴露,他们的区别？ 8、服务提供者能实现失效踢出是根据什么原理? 9、讲讲dubbo服务暴露中本地暴露,并画图辅助说明？ 10、一般选择什么注册中心,还有别的选择吗? 11、dubbo中zookeeper做注册中心,如果注册中心集群都挂掉,那发布者和订阅者还能通信吗?(面试高频题) 12、项目中有使用过多线程吗?有的话讲讲你在哪里用到了多线程?(面试高频题) 13、zookeeper的java客户端你使用过哪些? 14、服务提供者能实现失效踢出是什么原理？(高频题) 15、zookeeper的有哪些节点,他们有什么区别?讲一下应用场景。 16、画一画服务注册与发现的流程图。 17、在dubbo中,什么时候更新本地的zookeeper信息缓存文件?订阅zookeeper信息的整体过程是怎么样的? 18、谈一下你们项目架构设计(很多人在回答这个的时候都容易回答SSH或者SSM,注意,所谓是SSH这些是技术选型,不是架构的设计) 19、既然你们项目用到了dubbo,那你讲讲你们是怎么通过dubbo实现服务降级的,降级的方式有哪些,又有什么区别? 20、dubbo监控平台能够动态改变接口的一些设置,其原理是怎样的? 21、既然你说你看过dubbo源码,那讲一下有没有遇到过什么坑?(区分度高,也是检验是否看过源码的试金石) 22、dubbo的原理是怎么样的?请简单谈谈 23、有没有考虑过自己实现一个类似dubbo的RPC框架,如果有,请问你会如果着手实现?(面试高频题,区分度高) 24、你说你用过mybatis,那你知道Mapper接口的原理吗?(如果回答得不错,并且提到动态代理这个关键词会继续往下问,那这个动态代理又是如何通过依赖注入到Mapper接口的呢?) 25、描述一下dubbo服务引用的过程,原理 26、既然你提到了dubbo的服务引用中封装通信细节是用到了动态代理,那请问创建动态代理常用的方式有哪些,他们又有什么区别?dubbo中用的是哪一种?(高频题) 27、除了JDK动态代理和CGLIB动态代理外,还知不知道其他实现代理的方式?(区分度高) 28、你是否了解spi,讲一讲什么是spi,为什么要使用spi? 29、对类加载机制了解吗,说一下什么是双亲委托模式,他有什么弊端,这个弊端有没有什么我们熟悉的案例,解决这个弊端的原理又是怎么样的? 30、既然你对spi有一定了解,那么dubbo的spi和jdk的spi有区别吗?有的话,究竟有什么区别? 31、你提到了dubbo中spi也增加了IoC,那你先讲讲Spring的IoC,然后再讲讲dubbo里面又是怎么做的？ 32、你提到了dubbo中spi也增加了AOP,那你讲讲这用到了什么设计模式,dubbo又是如何做的？","link":"/2020/07/21/Dubbo/"},{"title":"JavaBasicProblem","text":"一些容易忘记的Java基础知识点：） Java基本数据类型 类型名称 关键字 占用内存 取值范围 字节型 byte 1字节 -128~127 短整型 short 2字节 -32768~32767 整型 int 4字节 -2147483648~2147483647 长整型 long 8字节 -9223372036854775808L~9223372036854775807L 单精度浮点型 float 4字节 +/-3.4E+38F（6~7 个有效位） 双精度浮点型 double 8字节 +/-1.8E+308 (15 个有效位） 字符型 char 2字节 ISO 单一字符集 布尔型 boolean 1字节 true 或 false 注：当需要将数值范围较大的数值类型赋给数值范围较小的数值类型变量时，此时可能会丢失精度，即强制类型转换。 123456public static void main(String[] args) { int a = 233; byte b = (byte) a; System.out.println(b);}// 输出：-23 原因：233的二进制为：24位0 + 11101001，而byte只有8位，于是从高位开始舍弃，最后剩下：11101001，由于二进制最高位1表示负数，0表示正数，故其十进制输出为-23。","link":"/2020/07/24/JavaBasicProblem/"},{"title":"Lc-1115","text":"Lc 1115.交替打印FooBar我们提供一个类： 12345678910111213class FooBar { public void foo() { for (int i = 0; i &lt; n; i++) { print(\"foo\"); } } public void bar() { for (int i = 0; i &lt; n; i++) { print(\"bar\"); } }} 两个不同的线程将会共用一个 FooBar 实例。其中一个线程将会调用 foo() 方法，另一个线程将会调用 bar() 方法。 请设计修改程序，以确保 “foobar” 被输出 n 次。 12345678910111213141516171819202122232425262728293031323334353637383940class FooBar { private int n; private boolean isFooTurn = true; private Object obj = new Object(); public FooBar(int n) { this.n = n; } public void foo(Runnable printFoo) throws InterruptedException { for (int i = 0; i &lt; n; i++) { synchronized (obj){ if (!isFooTurn){ obj.wait(); } // printFoo.run() outputs \"foo\". Do not change or remove this line. printFoo.run(); isFooTurn = false; obj.notifyAll(); } } } public void bar(Runnable printBar) throws InterruptedException { for (int i = 0; i &lt; n; i++) { synchronized (obj){ if (isFooTurn){ obj.wait(); } // printBar.run() outputs \"bar\". Do not change or remove this line. printBar.run(); isFooTurn = true; obj.notifyAll(); } } }} 优化123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class FooBar { private int n; private final Lock lock = new ReentrantLock(); private boolean allowedAProcess = true; private final Condition conditionA = lock.newCondition(); private final Condition conditionB = lock.newCondition(); public FooBar(int n) { this.n = n; } public void foo(Runnable printFoo) throws InterruptedException { for (int i = 0; i &lt; n; i++) { lock.lock(); try { while (!allowedAProcess) { conditionA.await(); } // printFoo.run() outputs \"foo\". Do not change or remove this line. printFoo.run(); allowedAProcess = false; conditionB.signalAll(); } finally { lock.unlock(); } } } public void bar(Runnable printBar) throws InterruptedException { for (int i = 0; i &lt; n; i++) { lock.lock(); try { while (allowedAProcess) { conditionB.await(); } // printBar.run() outputs \"bar\". Do not change or remove this line. printBar.run(); allowedAProcess = true; conditionA.signalAll(); } finally { lock.unlock(); } } }}","link":"/2020/07/16/Lc-1115/"},{"title":"Lc-1114","text":"Lc 1114.按序打印我们提供了一个类： public class Foo { public void one() { print(“one”); } public void two() { print(“two”); } public void three() { print(“three”); }}三个不同的线程将会共用一个 Foo 实例。 线程 A 将会调用 one() 方法线程 B 将会调用 two() 方法线程 C 将会调用 three() 方法请设计修改程序，以确保 two() 方法在 one() 方法之后被执行，three() 方法在 two() 方法之后被执行。 1234567891011121314151617181920212223242526272829303132333435363738class Foo { boolean firstFinished = false; boolean secondFinished = false; final Object obj = new Object(); public Foo() { } public void first(Runnable printFirst) throws InterruptedException { synchronized (obj) { // printFirst.run() outputs \"first\". Do not change or remove this line. printFirst.run(); firstFinished = true; } } public void second(Runnable printSecond) throws InterruptedException { synchronized (obj) { while (firstFinished) { // printSecond.run() outputs \"second\". Do not change or remove this line. printSecond.run(); secondFinished = true; } } } public void third(Runnable printThird) throws InterruptedException { synchronized (obj) { while (secondFinished) { // printThird.run() outputs \"third\". Do not change or remove this line. printThird.run(); } } }} 提交结果：超时 原因：while循环，不停抢占CPU资源来判断自身是否结束循环（自旋）。 优化使用wait+notify避免了自旋 1234567891011121314151617181920212223242526272829303132333435363738394041class Foo { final Object obj = new Object(); boolean firstFinished = false; boolean secondFinished = false; public Foo() { } public void first(Runnable printFirst) throws InterruptedException { synchronized (obj) { // printFirst.run() outputs \"first\". Do not change or remove this line. printFirst.run(); firstFinished = true; obj.notifyAll(); } } public void second(Runnable printSecond) throws InterruptedException { synchronized (obj) { while (!firstFinished) { obj.wait(); } // printSecond.run() outputs \"second\". Do not change or remove this line. printSecond.run(); secondFinished = true; obj.notifyAll(); } } public void third(Runnable printThird) throws InterruptedException { synchronized (obj) { while (!secondFinished) { obj.wait(); } // printThird.run() outputs \"third\". Do not change or remove this line. printThird.run(); } }} 优化：使用CountDownLatch（Semaphore同理） 1234567891011121314151617181920212223242526272829class Foo { CountDownLatch c2; CountDownLatch c3; public Foo() { c2 = new CountDownLatch(1); c3 = new CountDownLatch(1); } public void first(Runnable printFirst) throws InterruptedException { // printFirst.run() outputs \"first\". Do not change or remove this line. printFirst.run(); c2.countDown(); } public void second(Runnable printSecond) throws InterruptedException { c2.await(); // printSecond.run() outputs \"second\". Do not change or remove this line. printSecond.run(); c3.countDown(); } public void third(Runnable printThird) throws InterruptedException { c3.await(); // printThird.run() outputs \"third\". Do not change or remove this line. printThird.run(); }}","link":"/2020/07/13/Lc-1114/"},{"title":"Lcof09","text":"Lcof 09.用两个栈实现队列 用两个栈实现一个队列。队列的声明如下，请实现它的两个函数 appendTail 和 deleteHead ，分别完成在队列尾部插入整数和在队列头部删除整数的功能。(若队列中没有元素，deleteHead 操作返回 -1 ) 1234567891011121314151617181920212223242526272829303132333435class CQueue { Stack in; Stack out; int size; public CQueue() { in = new Stack&lt;&gt;(); out = new Stack&lt;&gt;(); size=0; } public void appendTail(int value) { in.push(value); size++; } public int deleteHead() { if(size==0){ return -1; } if (out.isEmpty()) { while (!in.isEmpty()) { out.push(in.pop()); } } size--; return (int) out.pop(); }}/** * Your CQueue object will be instantiated and called as such: * CQueue obj = new CQueue(); * obj.appendTail(value); * int param_2 = obj.deleteHead(); */ 优化因为Stack继承了Vector接口，而Vector底层是一个Object[]数组，所以要考虑空间扩容和移位的问题。 可以使用LinkedList来做Stack的容器，其本身结构是个双向链表，扩容消耗少。 1234567891011121314151617181920212223class CQueue { LinkedList&lt;Integer&gt; stack1; LinkedList&lt;Integer&gt; stack2; public CQueue() { stack1 = new LinkedList&lt;&gt;(); stack2 = new LinkedList&lt;&gt;(); } public void appendTail(int value) { stack1.add(value); } public int deleteHead() { if (stack2.isEmpty()) { if (stack1.isEmpty()) return -1; while (!stack1.isEmpty()) { stack2.add(stack1.pop()); } return stack2.pop(); } else return stack2.pop(); }} 关系图","link":"/2020/06/27/Lcof09/"},{"title":"Lcof10_1","text":"Lcof 10-1.斐波那契数列 写一个函数，输入 n ，求斐波那契（Fibonacci）数列的第 n 项。斐波那契数列的定义如下： F(0) = 0, F(1) = 1F(N) = F(N - 1) + F(N - 2), 其中 N &gt; 1. 斐波那契数列由 0 和 1 开始，之后的斐波那契数就是由之前的两数相加而得出。答案需要取模 1e9+7（1000000007），如计算初始结果为：1000000008，请返回 1。 1234567891011class Solution { public int fib(int n) { if (n == 0) { return 0; } else if (n == 1) { return 1; } else { return fib(n - 1) + fib(n - 2); } }} 提交结果：超时 原因： 大量重复的递归计算。 优化： 1234567891011class Solution { public int fib(int n) { int a = 0, b = 1, sum; for(int i = 0; i &lt; n; i++){ sum = (a + b) % 1000000007; a = b; b = sum; } return a; }}","link":"/2020/06/27/Lcof10-1/"},{"title":"Redis","text":"Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。 基础五种基本的数据结构字符串String底层结构底层类似Java中的ArrayList，从源码的 sds.h/sdshdr 文件中可以看到 Redis 底层对于字符串的定义 SDS，即 Simple Dynamic String 结构。在源码中同样一组结构Redis使用泛型定义了好多次，为什么不直接使用int类型？ 因为当字符串比较短时，len和alloc可以使用byte和short来表示，故为了优化内存，不同长度的字符串使用不同的结构体来表示。 SDS与C语言中字符串的区别SDS： 123456789101112131415161718192021222324252627282930/* Note: sdshdr5 is never used, we just access the flags byte directly. * However is here to document the layout of type 5 SDS strings. */struct __attribute__ ((__packed__)) sdshdr5 { unsignedchar flags; /* 3 lsb of type, and 5 msb of string length */ char buf[];};struct __attribute__ ((__packed__)) sdshdr8 { uint8_t len; /* used */ uint8_t alloc; /* excluding the header and null terminator */ unsignedchar flags; /* 3 lsb of type, 5 unused bits */ char buf[];};struct __attribute__ ((__packed__)) sdshdr16 { uint16_t len; /* used */ uint16_t alloc; /* excluding the header and null terminator */ unsignedchar flags; /* 3 lsb of type, 5 unused bits */ char buf[];};struct __attribute__ ((__packed__)) sdshdr32 { uint32_t len; /* used */ uint32_t alloc; /* excluding the header and null terminator */ unsignedchar flags; /* 3 lsb of type, 5 unused bits */ char buf[];};struct __attribute__ ((__packed__)) sdshdr64 { uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsignedchar flags; /* 3 lsb of type, 5 unused bits */ char buf[];}; C语言中使用长度为N+1的字符数组表示长度为N的字符串，且字符数组最后一个元素总是’\\0’，会造成如下问题： 获取字符串长度的时间复杂度总是O(N)，因为C语言的实现中没有保存数组的长度，每次都要遍历整个数组； 在拼接或截取字符串时，若操作不当，容易发生缓冲区溢出/内存泄漏的问题，原因同上； 只能保存文本数据，因为C语言中的字符串必须符合某种编码（如ASCII） 追加字符串，Redis源码如下：(Redis规定字符串不得超过512MB) 12345678910111213141516/* Append the specified binary-safe string pointed by 't' of 'len' bytes to the * end of the specified sds string 's'. * * After the call, the passed sds string is no longer valid and all the * references must be substituted with the new pointer returned by the call. */sds sdscatlen(sds s, const void *t, size_t len) { // 获取原字符串的长度 size_t curlen = sdslen(s); // 按需调整空间，如果容量不够容纳追加的内容，就会重新分配字节数组并复制原字符串的内容到新数组中 s = sdsMakeRoomFor(s,len); if (s == NULL) returnNULL; // 内存不足 memcpy(s+curlen, t, len); // 追加目标字符串到字节数组中 sdssetlen(s, curlen+len); // 设置追加后的长度 s[curlen+len] = '\\0'; // 让字符串以 \\0 结尾，便于调试打印 return s;} 基本操作/命令设置和获取键值对（key存在时，SET命令会直接覆盖旧的值） 批量设置键值对 过期和SET命令扩展 计数：如果 value 是一个整数，还可以对它使用 INCR 命令进行 原子性 的自增操作，这意味着及时多个客户端对同一个 key 进行操作，也决不会导致竞争的情况。 12345&gt; SET counter 100&gt; INCR count(interger) 101&gt; INCRBY counter 50(integer) 151 返回原值的GETSET命令 应用 缓存功能：String字符串是最常用的数据类型，不仅仅是Redis，各个语言都是最基本类型，因此，利用Redis作为缓存，配合其它数据库作为存储层，利用Redis支持高并发的特点，可以大大加快系统的读写速度、以及降低后端数据库的压力。 计数器：许多系统都会使用Redis作为系统的实时计数器，可以快速实现计数和查询的功能。而且最终的数据结果可以按照特定的时间落地到数据库或者其它存储介质当中进行永久保存。 共享用户Session：用户重新刷新一次界面，可能需要访问一下数据进行重新登录，或者访问页面缓存Cookie，但是可以利用Redis将用户的Session集中管理，在这种模式只需要保证Redis的高可用，每次用户Session的更新和获取都可以快速完成。大大提高效率。 列表list底层类似于Java中的LinkedList，故删除/插入极快O(1)，索引定位慢O(n)。 基本操作 LPUSH和RPUSH分别可以向 list 的左边（头部）和右边（尾部）添加一个新元素； LRANGE命令可以从 list 中取出一定范围的元素； LINDEX命令可以从 list 中取出指定下表的元素，相当于 Java 链表操作中的get(int index)操作； list实现队列12345678910&gt; RPUSH books python java golang(integer) 3&gt; LPOP books\"python\"&gt; LPOP books\"java\"&gt; LPOP books\"golang\"&gt; LPOP books(nil) list实现栈123456789&gt; RPUSH books python java golang&gt; RPOP books\"golang\"&gt; RPOP books\"java\"&gt; RPOP books\"python\"&gt; RPOP books(nil) 应用 消息队列：Redis的链表结构，可以轻松实现阻塞队列，可以使用左进右出的命令组成来完成队列的设计。比如：数据的生产者可以通过Lpush命令从左边插入数据，多个数据消费者，可以使用BRpop命令阻塞的“抢”列表尾部的数据。 文章列表或者数据分页展示的应用。比如，常用的博客网站的文章列表，当用户量越来越多时，而且每一个用户都有自己的文章列表，而且当文章多时，都需要分页展示，这时可以考虑使用Redis的列表，列表不但有序同时还支持按照范围内获取元素，可以完美解决分页查询功能。大大提高查询效率。 字典hash底层结构类似于Java中的HashMap，内部实现也类似，通过”数组 + 链表”的链地址法来解决部分哈希冲突，同时这样的结构也吸收了两种不同数据结构的优点。 12345678910111213141516171819typedefstruct dictht { // 哈希表数组 dictEntry **table; // 哈希表大小 unsignedlong size; // 哈希表大小掩码，用于计算索引值，总是等于 size - 1 unsignedlong sizemask; // 该哈希表已有节点的数量 unsignedlong used;} dictht;typedefstruct dict { dictType *type; void *privdata; // 内部有两个 dictht 结构 dictht ht[2]; long rehashidx; /* rehashing not in progress if rehashidx == -1 */ unsignedlong iterators; /* number of iterators currently running */} dict; table 属性是一个数组，数组中的每个元素都是一个指向 dict.h/dictEntry 结构的指针，而每个 dictEntry 结构保存着一个键值对： 12345678910111213typedefstruct dictEntry { // 键 void *key; // 值 union { void *val; uint64_t u64; int64_t s64; double d; } v; // 指向下个哈希表节点，形成链表 struct dictEntry *next;} dictEntry; 从源码中可以看到dict中包含两个dicht，通常情况下只有一个dicht是有值的，但在字典扩容缩容时需要分配新的dicht，进行渐进式搬迁（会在rehash的同时保留新旧两个hash结构，在后续的定时任务以及hash操作指令中，逐渐把旧字典的内容迁移到新字典中，当搬迁完成，使用新的hash结构取而代之。） 扩容条件条件：hash表中元素的个数等于第一维数组的长度时。 容量：扩容的新数组是原数组大小的2倍。 特殊情况：Redis正在执行bgsave时（持久化命令），Redis尽量不扩容，当hash表达到第一维数组长度5倍时，会执行强制扩容。 缩容条件条件：元素个数低于数组长度的10% 缩容不会考虑Redis是否在做bgsave。 字典的基本操作123456789101112131415&gt; HSET books java \"think in java\" # 命令行的字符串如果包含空格则需要使用引号包裹(integer) 1&gt; HSET books python \"python cookbook\"(integer) 1&gt; HGETALL books # key 和 value 间隔出现1) \"java\"2) \"think in java\"3) \"python\"4) \"python cookbook\"&gt; HGET books java\"think in java\"&gt; HSET books java \"head first java\" (integer) 0 # 因为是更新操作，所以返回 0&gt; HMSET books java \"effetive java\" python \"learning python\" # 批量操作OK 应用这个是类似Map的一种结构，一般可以将结构化的数据，比如一个对象（前提是这个对象没嵌套其他的对象）给缓存在Redis里，然后每次读写缓存的时候，可以就操作Hash里的某个字段。 集合set类似于Java中的HashSet，内部的键值对是无序的，唯一的。内部实现相当于一个特殊的字典，字典中所有的value都是NULL。 基本操作123456789101112131415&gt; HSET books java \"think in java\" # 命令行的字符串如果包含空格则需要使用引号包裹(integer) 1&gt; HSET books python \"python cookbook\"(integer) 1&gt; HGETALL books # key 和 value 间隔出现1) \"java\"2) \"think in java\"3) \"python\"4) \"python cookbook\"&gt; HGET books java\"think in java\"&gt; HSET books java \"head first java\" (integer) 0 # 因为是更新操作，所以返回 0&gt; HMSET books java \"effetive java\" python \"learning python\" # 批量操作OK 有序列表zset底层实现基于跳跃表 基本操作1234567891011121314151617181920212223242526272829303132333435363738&gt; ZADD books 9.0 \"think in java\"&gt; ZADD books 8.9 \"java concurrency\"&gt; ZADD books 8.6 \"java cookbook\"&gt; ZRANGE books 0 -1 # 按 score 排序列出，参数区间为排名范围1) \"java cookbook\"2) \"java concurrency\"3) \"think in java\"&gt; ZREVRANGE books 0 -1 # 按 score 逆序列出，参数区间为排名范围1) \"think in java\"2) \"java concurrency\"3) \"java cookbook\"&gt; ZCARD books # 相当于 count()(integer) 3&gt; ZSCORE books \"java concurrency\" # 获取指定 value 的 score\"8.9000000000000004\" # 内部 score 使用 double 类型进行存储，所以存在小数点精度问题&gt; ZRANK books \"java concurrency\" # 排名(integer) 1&gt; ZRANGEBYSCORE books 0 8.91 # 根据分值区间遍历 zset1) \"java cookbook\"2) \"java concurrency\"&gt; ZRANGEBYSCORE books -inf 8.91 withscores # 根据分值区间 (-∞, 8.91] 遍历 zset，同时返回分值。inf 代表 infinite，无穷大的意思。1) \"java cookbook\"2) \"8.5999999999999996\"3) \"java concurrency\"4) \"8.9000000000000004\"&gt; ZREM books \"java concurrency\" # 删除 value(integer) 1&gt; ZRANGE books 0 -11) \"java cookbook\"2) \"think in java\" 应用有序集合的使用场景与集合类似，但是set集合不是自动有序的，而Sorted set可以利用分数进行成员间的排序，而且是插入时就排序好。所以当需要一个有序且不重复的集合列表时，就可以选择Sorted set数据结构作为选择方案。 排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。例如微博热搜榜。 用Sorted Sets来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。 不基本的数据结构BitMap通过一个bit位来表示某个元素对应的值或者状态，key就是对应元素本身。可以将其想象成以位为单位的数组，数组的每个单元只能存储0和1，数组的下标叫做偏移量。 优势：极大的节省储存空间。 基本操作1&gt; SETBIT key offset value 返回值：指定偏移量上原来存储的bit 1&gt; GETBIT key offset 说明：获取指定偏移量上的bit，当offset比字符串值的长度大，或者key不存在时，返回0。 1&gt; BITCOUNT key start end 说明：计算给定字符串中，指定的偏移量上，被设置为1的位的数量。 应用用户签到 统计活跃用户 HyperLogLog供不精确的去重技术功能，适合做大规模数据的去重统计。 Redis ModuleBloomFilter底层基于BitMap，由一个位数组和K个哈希函数组成。 当一个元素加入布隆过滤器时，会经历如下步骤： 1）使用K个哈希函数对元素进行K次计算，得到K个哈希值； 2）在位数组中根据得到的哈希值，把对应的下标的值置为1； 优点：空间效率高，占用空间小，查询效率高； 存在的问题：当插入的元素越来越多，即位数组中被置为1的位置也越多，当一个不在布隆过滤器中的元素，经过哈希计算之后，得到的值在位数组中查询，有可能这些位置也都被置为1，即导致误判。 主要命令： bf.add添加元素到布隆过滤器中； bf.exists判断某个元素是否在过滤器中； 在redis中有两个值决定布隆过滤器的准确率： error_rate：允许布隆过滤器的错误率，这个值越低过滤器的位数组的大小越大，占用空间也就越大； initial_size：布隆过滤器可以储存的元素个数，当实际存储的元素个数超过这个值之后，过滤器的准确率会下降； redis 中有一个命令可以来设置这两个值： 1bf.reserve urls 0.01 100 第一个参数是过滤器的名字； 第二个参数是error_rate的值； 第三个参数是initial_size的值； Redis Module，如BloomFilter，RedisSearch，RedisML Redis的持久化因为Redis数据全部保存在内存中，如果突然宕机，数据就会全部丢失，所以Redis持久化机制应运而生，即将内存中的数据保存到磁盘中。 持久化的过程客户端向数据库发出写命令，数据库接收到客户端的写请求后，调用系统API将数据写入磁盘，操作系统将写缓冲区传输到磁盘控制器，然后由磁盘控制器将数据写入实际的物理媒介中。 数据流向： 客户端的内存 -&gt; 服务器的内存 -&gt; 内核缓冲区 -&gt; 磁盘缓存 -&gt; 磁盘 方式一：快照 RDB原理：系统多进程Copy On Write机制 + fork函数 快照将生成一个包含整个数据集的.rdb文件。 fork创建子进程过程： 分配新的内存块和内核数据结构给子进程； 将父进程部分数据结构内容拷贝给子进程； 添加子进程到系统进程列表中； fork返回，开始调度器调度； Redis在持久化时会调用glibc的函数fork产生一个子进程（共享代码块和数据段），将快照持久化交给子进程处理，父进程则继续处理客户端请求。 父进程对内存数据结构进行修改，会对子进程造成影响么？ 不会，因为此时使用操作系统的COW机制进行数据段页面的分离，数据段是由很多操作系统的页面组成，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复制一份分离出来，对这个复制的页面进行修改。这时子进程 相应的页面并没有变化，还是进程产生时的数据。 缺点：如果快照保存完成前宕机，这段时间写入Redis的最新数据将会丢失；在生成数据快照时，如果文件很大，客户端可能会暂停几毫秒甚至几秒。 方式二：AOFAppend Only File，每次执行修改内存中数据集的写操作时，都会记录该操作。有灵活的同步策略，no，always，every seconds。 缺点：相同规模的数据集，AOF大于RDB；运行效率低于RDB。 原理：AOF日志是以文件的形式存在的，当程序对AOF日志文件进行写操作时，实际上是将内容写到了内核为文件描述符分配的一个内存缓存中，然后内核会通过glibc提供的fsync(int fd)函数，异步将指定文件内容强制从内核缓存刷到磁盘。 优化Redis提供了bgrewriteaof指令用于对AOF日志进行瘦身。 原理：开辟一个子进程对内存进行遍历转换成一系列Redis的操作指令，序列化到一个新的AOF日志文件中。序列化完成后再将操作期间发生的增量AOF日志追加到这个新的AOF日志文件中，追加完毕后就立即替代旧的AOF日志文件了，瘦身工作就完成了。 混合持久化Redis4.0开始提供。将rdb文件的内容和增量的AOF日志文件存在一起。这里的 AOF日志不再是全量的日志，而是自持久化开始到持久化结束的这段时间发生的增量AOF日志，通常这部分AOF日志很小。于是重启Redis时，可以先加载rdb的内容，然后再重放增量AOF日志，重启效率大幅提升。 常见场景缓存雪崩原因：缓存服务器重启或key同时失效，请求全部落到数据库。 方案： 1）在Redis中批量存数据时，将key的失效时间设为随机值，让缓存失效时间尽量均匀； 2）设置热点数据永不过期，有更新操作就手动更新缓存； 缓存穿透原因：缓存和数据库中都没有的数据，用户不断发起请求。（比如用一个不存在的用户id获取用户信息，不论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库。） 方案： 1）如果一个查询返回的数据为空，将这个空结果进行缓存，但过期时间需设置很短； 2）将所有可能存在的数据放到一个足够大的布隆过滤器中，一定不存在的数据会被拦截掉，从而避免了对数据库的查询压力； 3）增加参数校验； 缓存击穿原因：缓存中没有数据但数据库中有数据（缓存时间到期） 方案： 1）设置热点数据永远不过期； 2）加上互斥锁； 1234567891011121314151617181920212223public static String getData(String Key) throws InterruptedException { // 从Redis查询数据 String result = getDataByKV(Key); // 校验 if (StringUtils.isBlank(result)) { // 获取锁 if (reenLock.trylock()) { // 去数据库查询 result = getDataByDB(Key); // 校验 if (StringUtils.isBlank(result)) { // 放入缓存 setDataToKV(Key, result); } // 释放锁 reenLock.unLock(); } else { Thread.sleep(100L); result = getData(key); } } return result;} 六种Key的淘汰策略Redis中通过maxmemory参数来设定内存的使用上限，当Redis使用内存达到设定的最大值时，会根据配置文件中的策略删除key，从而给新的键值留出空间。 目前Redis提供了6种的淘汰策略（默认的是noeviction）： volatile-lru：在设置了过期时间的键空间中，移除最近最少使用的key； allkeys-lru：移除最近最少使用的key； volatile-random，在设置了过期时间的键空间中，随机移除一个key； allkeys-random，随机移除一个key； volatile-ttl，在设置了过期时间的键空间中，优先回收存活时间（TTL）较短的键，即移除将要过期的key； noeviction：当内存使用达到阀值的时候，所有引起申请内存的命令会报错； 三种删除过期key策略 定时删除 在设置某个key的过期时间同时，创建一个定时器，让定时器在该过期时间到来时，立即执行删除操作。 缺点：在过期键比较多时，删除过期键会占用一部分CPU时间，对服务器的响应时间和吞吐量造成影响。 惰性删除 放任键过期不管，每次获取键时，都检查取得的键是否过期，若过期，删除即可。 缺点：如果多个键都已经过期，而这些键又恰好没有被访问，那么这部分的内存就都不会被释放。 定期删除 Redis会周期性的随机检查设置了过期时间的key，删除里面过期的key。 缺点：难以确定操作执行的频率。 应用Redis集群主从之间的数据同步master负责写，将数据同步给slave，slave负责读，分发掉大量请求，并且可以实现水平扩容。 启动一台slave时，发送psync命令给master，如果这个slave是第一次连接到master，则会触发一个全量复制，即master启动一个线程生成RDB快照，并将新的写请求缓存在内存中，RDB文件生成后，master将其发送给slave，slave拿到后写进本地磁盘，然后加载进内存，之后master会把内存中缓存的新命令发给slave。 从节点可以执行写命令么？ 可以，修改redis.conf中slave-read-only 设置为no，即可执行写命令，但从节点写命令的数据，其他从节点或主节点是不能获取的。 哨兵模式基于主从模式的优化：当主节点挂掉后，从节点能够自动变成主节点。 工作方式三个定时任务： 1）每10秒，每个sentinel对master和slave执行info命令：用来发现slave节点；确定主从关系。 2）每2秒，每个sentinel通过master节点的channel（名称为sentinel:hello）交换信息（pub/sub）：用来交互对节点的看法以及自身信息。 3）每1秒，每个sentinel对其他sentinel和redis执行ping命令，用于心跳检测，作为节点存活的判断依据。 如果一个实例（instance）距离最后一次有效回复PING命令的时间超过down-after-milliseconds选项所指定的值， 则这个实例会被Sentinel进程标记为主观下线SDOWN； 当有足够数量的Sentinel进程（大于等于配置文件指定的值）在指定时间范围内确认Master进入了主观下线状态SDOWN， 则Master会被标记为客观下线ODOWN；（此时开启故障转移机制） 当Master被Sentinel进程标记为ODOWN后，Sentinel进程向下线的Master的所有Slave发送INFO命令的频率会从10秒一次改为1秒一次； 哨兵组件的主要功能： 集群监控：负责监控Redis master和slave进程是否正常工作； 消息通知：如果某个Redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员； 故障转移：如果 master node 挂掉了，会自动转移到slave node上； 例子： 当master出现故障，此时3个Sentinel节点共同选举了Sentinel3作为领导，负载处理主节点的故障转移： 将slave-1脱离原从节点，升级为master； 将从节点slave-2指向新的主节点； 通知客户端master已更换； 将原主节点（oldMaster）变成slave，指向新的master； 配置中心：如果故障转移发生了，通知client客户端新的master地址； 缺点：较难支持在线扩容，在集群容量达到上限时在线扩容会很复杂；每台redis存储相同数据，浪费内存； Redis-ClusterRedis3.0，实现了redis的分布式存储，即每台redis上存储不同的内容。 Redis-Cluster采用无中心结构，特点如下： 所有的节点彼此互联（PING-PONG机制），内部使用二进制协议优化传输速度和带宽； 节点的fail是通过集群中超过半数的节点检测失效时才生效； 客户端与redis节点直连,不需要中间代理层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可； 工作方式每一个节点上，都有两个部分：插槽（slot），它的的取值范围是：0-16383；cluster，可以理解为是一个集群管理的插件。当存取的key到达时，redis会根据crc16的算法得出一个结果，然后把结果对16384求余数，这样每个key都会对应一个编号在0-16383之间的哈希槽，通过这个值，找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作。 从redis中没有slot，不会参与集群投票，仅仅作为主机的备份。 为了保证高可用，redis-cluster集群引入了主从模式，一个主节点对应一个或者多个从节点，当主节点宕机的时候，就会启用从节点。当其它主节点ping一个主节点A时，如果半数以上的主节点与A通信超时，那么认为主节点A宕机了。 什么情况下集群不可用？ 任意主节点和它的从节点都宕机了； 集群中超过半数的master挂掉，无论是否有slave，集群都进入fail状态； Redis分布式锁","link":"/2020/07/25/Redis/"},{"title":"SomeSynchronizationTool","text":"同步工具 类 作用 Semaphore 限制线程的数量 Exchanger 两个线程交换数据 CountDownLatch 线程等待直到计数器减为0时开始工作 CyclicBarrier 作用跟CountDownLatch类似，但是可以重复使用 Phaser 增强的CyclicBarrier Semaphore源码分析内部有一个继承了AQS的同步器Sync，重写了tryAcquireShared方法。在这个方法里，会去尝试获取资源。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Creates a {@code Semaphore} with the given number of * permits and nonfair fairness setting. * * @param permits the initial number of permits available. * This value may be negative, in which case releases * must occur before any acquires will be granted. */// 默认情况下使用非公平public Semaphore(int permits) { sync = new NonfairSync(permits);}/** * Creates a {@code Semaphore} with the given number of * permits and the given fairness setting. * * @param permits the initial number of permits available. * This value may be negative, in which case releases * must occur before any acquires will be granted. * @param fair {@code true} if this semaphore will guarantee * first-in first-out granting of permits under contention, * else {@code false} */public Semaphore(int permits, boolean fair) { sync = fair ? new FairSync(permits) : new NonfairSync(permits);}final int nonfairTryAcquireShared(int acquires) { for (;;) { int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; }}// 如果阻塞队列没有等待的线程，则参与许可的竞争；否则直接插入到阻塞队列尾节点并挂起，等待唤醒protected int tryAcquireShared(int acquires) { for (;;) { if (hasQueuedPredecessors()) return -1; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; }} demo12345678910111213141516171819202122232425262728293031public class SemaphoreDemo { static Semaphore semaphore = new Semaphore(5, true); public static void main(String[] args) { ExecutorService service = Executors.newFixedThreadPool(50); for (int i = 0; i &lt; 100; i++) { service.submit(new Task()); } service.shutdown(); } static class Task implements Runnable { @Override public void run() { try { semaphore.acquire(3); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \"拿到了许可证\"); try { Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \"释放了许可证\"); semaphore.release(2); } }} 适用场景可以用来做流量分流，特别是对公共资源有限的场景； Exchanger用于两个线程交换数据，支持泛型。 源码分析使用park/unpark来实现等待状态的切换 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * Waits for another thread to arrive at this exchange point (unless * the current thread is {@linkplain Thread#interrupt interrupted}), * and then transfers the given object to it, receiving its object * in return. * * &lt;p&gt;If another thread is already waiting at the exchange point then * it is resumed for thread scheduling purposes and receives the object * passed in by the current thread. The current thread returns immediately, * receiving the object passed to the exchange by that other thread. * * &lt;p&gt;If no other thread is already waiting at the exchange then the * current thread is disabled for thread scheduling purposes and lies * dormant until one of two things happens: * &lt;ul&gt; * &lt;li&gt;Some other thread enters the exchange; or * &lt;li&gt;Some other thread {@linkplain Thread#interrupt interrupts} * the current thread. * &lt;/ul&gt; * &lt;p&gt;If the current thread: * &lt;ul&gt; * &lt;li&gt;has its interrupted status set on entry to this method; or * &lt;li&gt;is {@linkplain Thread#interrupt interrupted} while waiting * for the exchange, * &lt;/ul&gt; * then {@link InterruptedException} is thrown and the current thread's * interrupted status is cleared. * * @param x the object to exchange * @return the object provided by the other thread * @throws InterruptedException if the current thread was * interrupted while waiting */@SuppressWarnings(\"unchecked\")public V exchange(V x) throws InterruptedException { Object v; Object item = (x == null) ? NULL_ITEM : x; // translate null args if ((arena != null || (v = slotExchange(item, false, 0L)) == null) &amp;&amp; ((Thread.interrupted() || // disambiguates null return (v = arenaExchange(item, false, 0L)) == null))) throw new InterruptedException(); return (v == NULL_ITEM) ? null : (V)v;}// 如果在指定时间内没有另一个线程调用exchange，会抛出超时异常。@SuppressWarnings(\"unchecked\")public V exchange(V x, long timeout, TimeUnit unit) throws InterruptedException, TimeoutException { Object v; Object item = (x == null) ? NULL_ITEM : x; long ns = unit.toNanos(timeout); if ((arena != null || (v = slotExchange(item, true, ns)) == null) &amp;&amp; ((Thread.interrupted() || (v = arenaExchange(item, true, ns)) == null))) throw new InterruptedException(); if (v == TIMED_OUT) throw new TimeoutException(); return (v == NULL_ITEM) ? null : (V)v;} demo1234567891011121314151617181920212223242526public class ExchangerDemo { public static void main(String[] args) throws InterruptedException { Exchanger&lt;String&gt; exchanger = new Exchanger&lt;&gt;(); new Thread(() -&gt; { try { System.out.println(\"这是线程A，得到了另一个线程的数据：\" + exchanger.exchange(\"这是来自线程A的数据\")); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); System.out.println(\"这个时候线程A是阻塞的，在等待线程B的数据\"); Thread.sleep(1000); new Thread(() -&gt; { try { System.out.println(\"这是线程B，得到了另一个线程的数据：\" + exchanger.exchange(\"这是来自线程B的数据\")); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); }} 适用场景一般用于两个线程之间更方便地在内存中交换数据，因为其支持泛型，所以可以传输任何的数据，比如IO流或者IO缓存。根据JDK中的注释，可总结如下： 此类提供对外的操作是同步的； 用于成对出现的线程之间交换数据； 可以视作双向的同步队列； 可应用于基因算法、流水线设计等场景； 当三个线程调用同一个实例的exchange方法时，只有前两个线程会交换数据，第三个线程会进入阻塞状态。 需要注意的是，exchange是可以重复使用的。也就是说。两个线程可以使用Exchanger在内存中不断地再交换数据。 CountDownLatchCountDownLatch用一个给定的计数器来初始化，该计数器的操作是原子操作，即同时只能有一个线程去操作该计数器。调用该类await()的线程会一直处于阻塞状态，直到其他线程调用countDown()使当前计数器的值变为零（每次调用countDown计数器的值减1）。当计数器值减至零时，所有因调用await()而处于等待状态的线程就会继续往下执行。这种现象只会出现一次，因为计数器不能被重置，如果业务上需要一个可以重置计数次数的版本，可以考虑使用CycliBarrier。 原理分析内部有一个继承了AQS的同步器Sync demo123456789101112131415161718192021222324252627282930313233343536/** * 描述： 模拟100米跑步，5名选手都准备好了，只等裁判员一声令下，所有人同时开始跑步。当所有人都到终点后，比赛结束。 */public class CountDownLatchDemo1And2 { public static void main(String[] args) throws InterruptedException { CountDownLatch begin = new CountDownLatch(1); CountDownLatch end = new CountDownLatch(5); ExecutorService service = Executors.newFixedThreadPool(5); for (int i = 0; i &lt; 5; i++) { final int no = i + 1; Runnable runnable = new Runnable() { @Override public void run() { System.out.println(\"No.\" + no + \"准备完毕，等待发令枪\"); try { begin.await(); System.out.println(\"No.\" + no + \"开始跑步了\"); Thread.sleep((long) (Math.random() * 10000)); System.out.println(\"No.\" + no + \"跑到终点了\"); } catch (InterruptedException e) { e.printStackTrace(); } finally { end.countDown(); } } }; service.submit(runnable); } //裁判员检查发令枪... Thread.sleep(3000); System.out.println(\"发令枪响，比赛开始！\"); begin.countDown(); end.await(); System.out.println(\"所有人到达终点，比赛结束\"); }} 适用场景程序执行需要等待某个条件完成后才能继续执行后续的操作；如并行计算，当某个处理的运算量很大时，可以将该运算任务拆分成多个子任务，等待所有的子任务都完成之后，父任务再拿到所有子任务的运算结果进行汇总。 CyclicBarrier类似于CountDownLatch，它也是通过计数器来实现的。当某个线程调用await方法时，该线程进入等待状态，且计数器加1，当计数器的值达到设置的初始值时，所有因调用await进入等待状态的线程被唤醒，继续执行后续操作。因为CycliBarrier在释放等待线程后可以重用，所以称为循环barrier。CycliBarrier支持一个可选的Runnable，在计数器的值到达设定值后（但在释放所有线程之前），该Runnable运行一次，Runnable在每个屏障点只运行一个。 原理分析虽然功能与CountDownLatch类似，但是实现原理却完全不同，CyclicBarrier内部使用的是Lock + Condition实现的等待/通知模式。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * Main barrier code, covering the various policies. */private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException,TimeoutException { final ReentrantLock lock = this.lock; lock.lock(); try { final Generation g = generation; if (g.broken) throw new BrokenBarrierException(); if (Thread.interrupted()) { breakBarrier(); throw new InterruptedException(); } int index = --count; if (index == 0) { // tripped boolean ranAction = false; try { final Runnable command = barrierCommand; if (command != null) command.run(); ranAction = true; nextGeneration(); return 0; } finally { if (!ranAction) breakBarrier(); } } // loop until tripped, broken, interrupted, or timed out for (;;) { try { if (!timed) trip.await(); else if (nanos &gt; 0L) nanos = trip.awaitNanos(nanos); } catch (InterruptedException ie) { if (g == generation &amp;&amp; ! g.broken) { breakBarrier(); throw ie; } else { // We're about to finish waiting even if we had not // been interrupted, so this interrupt is deemed to // \"belong\" to subsequent execution. Thread.currentThread().interrupt(); } } if (g.broken) throw new BrokenBarrierException(); if (g != generation) return index; if (timed &amp;&amp; nanos &lt;= 0L) { breakBarrier(); throw new TimeoutException(); } } } finally { lock.unlock(); }} demo123456789101112131415161718192021222324252627282930313233343536public class CyclicBarrierDemo { public static void main(String[] args) { CyclicBarrier cyclicBarrier = new CyclicBarrier(5, new Runnable() { @Override public void run() { System.out.println(\"所有人都到场了， 大家统一出发！\"); } }); for (int i = 0; i &lt; 10; i++) { new Thread(new Task(i, cyclicBarrier)).start(); } } static class Task implements Runnable { private int id; private CyclicBarrier cyclicBarrier; public Task(int id, CyclicBarrier cyclicBarrier) { this.id = id; this.cyclicBarrier = cyclicBarrier; } @Override public void run() { System.out.println(\"线程\" + id + \"现在前往集合地点\"); try { Thread.sleep((long) (Math.random() * 10000)); System.out.println(\"线程\" + id + \"到了集合地点，开始等待其他人到达\"); cyclicBarrier.await(); System.out.println(\"线程\" + id + \"出发了\"); } catch (InterruptedException | BrokenBarrierException e) { e.printStackTrace(); } } }} Barrier被破坏如果线程在等待的过程中，Barrier被破坏，就会抛出BrokenBarrierException。可以用isBroken()方法检测Barrier是否被破坏。 如果有线程已经处于等待状态，调用reset方法会导致已经在等待的线程出现BrokenBarrierException异常。并且由于出现了BrokenBarrierException，将会导致始终无法等待； 如果在等待的过程中，线程被中断，也会抛出BrokenBarrierException异常，并且这个异常会传播到其他所有的线程； 如果在执行屏障操作过程中发生异常，则该异常将传播到当前线程中，其他线程会抛出BrokenBarrierException，屏障被损坏； 如果超出指定的等待时间，当前线程会抛出TimeoutException 异常，其他线程会抛出BrokenBarrierException异常； Phaser","link":"/2020/07/17/SomeSynchronizationTool/"},{"title":"RedisDistributedLock","text":"分布式锁特点 互斥性： 同一时刻只能有一个线程持有锁； 可重入性： 同一节点上的同一个线程如果获取了锁之后能够再次获取锁； 锁超时：和J.U.C中的锁一样支持锁超时，防止死锁； 高性能和高可用： 加锁和解锁需要高效，同时也需要保证高可用，防止分布式锁失效； 具备阻塞和非阻塞性：能够及时从阻塞状态中被唤醒； 实现方式 基于数据库 基于Redis 基于zookeeper 基于Redis实现的分布式锁利用 setnx + expire 命令（错误的做法）SETNX key value SETNX 是『SET if Not eXists』(如果不存在，则 SET)的简写。 只在键 key 不存在的情况下， 将键 key 的值设置为 value；若键 key 已经存在， 则 SETNX 命令不做任何动作。 返回值：命令在设置成功时返回 1 ， 设置失败时返回 0 。 因为分布式锁还需要超时机制，所以我们利用expire命令来设置，所以利用 SETNX + expire 命令的核心代码如下： 123456789public boolean tryLock(String key,String requset,int timeout) { Long result = jedis.setnx(key, requset); // result = 1时，设置成功，否则设置失败 if (result == 1L) { return jedis.expire(key, timeout) == 1L; } else { return false; }} 存在问题：SETNX 和 expire 是分开的两步操作，不具有原子性，如果执行完第一条指令应用异常或者重启了，锁将无法过期。 使用 SET key value [EX seconds] [PX milliseconds] [NX | XX] 命令（正确做法）如果 key 已经持有其他值，SET 就覆写旧值， 无视类型；当 SET 命令对一个带有生存时间（TTL）的键进行设置之后，该键原有的 TTL 将被清除。 从 Redis 2.6.12 版本开始， SET 命令的行为可以通过一系列参数来修改： EX seconds ：将键的过期时间设置为 seconds 秒。执行 SET key value EX seconds 的效果等同于执行 SETEX key seconds value ； PX milliseconds ：将键的过期时间设置为 milliseconds 毫秒。 执行 SET key value PX milliseconds 的效果等同于执行 PSETEX key milliseconds value； NX ：只在键不存在时， 才对键进行设置操作。 执行 SET key value NX 的效果等同于执行 SETNX key value； XX ：只在键已经存在时， 才对键进行设置操作； 123public boolean tryLock_with_set(String key, String UniqueId, int seconds) { return \"OK\".equals(jedis.set(key, UniqueId, \"NX\", \"EX\", seconds));} value必须要具有唯一性，我们可以用UUID来做，设置随机字符串保证唯一性，至于为什么要保证唯一性？假如value不是随机字符串，而是一个固定值，那么就可能存在下面的问题： 客户端1获取锁成功； 客户端1在某个操作上阻塞了太长时间； 设置的key过期了，锁自动释放了； 客户端2获取到了对应同一个资源的锁； 客户端1从阻塞中恢复过来，因为value值一样，所以执行释放锁操作时就会释放掉客户端2持有的锁，这样就会造成问题； 所以通常来说，在释放锁时，我们需要对value进行验证。 释放锁的实现释放锁时需要验证value值，也就是说我们在获取锁的时候需要设置一个value，不能直接用del key这种粗暴的方式，因为直接del key任何客户端都可以进行解锁了，所以解锁时，我们需要判断锁是否是自己的，基于value值来判断，代码如下： 12345public boolean releaseLock_with_lua(String key,String value) { String luaScript = \"if redis.call('get',KEYS[1]) == ARGV[1] then \" + \"return redis.call('del',KEYS[1]) else return 0 end\"; return jedis.eval(luaScript, Collections.singletonList(key), Collections.singletonList(value)).equals(1L);} 这里使用Lua脚本的方式，尽量保证原子性。使用 set key value [EX seconds][PX milliseconds][NX|XX] 命令 看上去很OK，实际上在Redis集群的时候也会出现问题，比如说A客户端在Redis的master节点上拿到了锁，但是这个加锁的key还没有同步到slave节点，master故障，发生故障转移，一个slave节点升级为master节点，B客户端也可以获取同个key的锁，但客户端A也已经拿到锁了，这就导致多个客户端都拿到锁。所以针对Redis集群这种情况，还有其他方案。 Redlock算法 与 Redisson 实现 Redlock 算法 Redisson 实现 Jedis 是阻塞式I/O，而 Redisson 底层使用Netty可以实现非阻塞I/O，该客户端封装了锁的，继承了 J.U.C 的Lock接口，所以我们可以像使用 ReentrantLock 一样使用 Redisson ，具体使用过程如下。 12345&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.10.6&lt;/version&gt;&lt;/dependency&gt; 1234567891011121314151617181920// 1. 配置文件Config config = new Config();config.useSingleServer() .setAddress(\"redis://127.0.0.1:6379\") .setPassword(RedisConfig.PASSWORD) .setDatabase(0);//2. 构造RedissonClientRedissonClient redissonClient = Redisson.create(config);//3. 设置锁定资源名称RLock lock = redissonClient.getLock(\"redlock\");lock.lock();try { System.out.println(\"获取锁成功，实现业务逻辑\"); Thread.sleep(10000);} catch (InterruptedException e) { e.printStackTrace();} finally { lock.unlock();} Redis 实现的分布式锁轮子自定义注解被注解的方法会执行获取分布式锁的逻辑 12345678910111213141516171819202122232425262728293031@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Documented@Inheritedpublic @interface RedisLock { /** * 业务键 * * @return */ String key(); /** * 锁的过期秒数,默认是5秒 * * @return */ int expire() default 5; /** * 尝试加锁，最多等待时间 * * @return */ long waitTime() default Long.MIN_VALUE; /** * 锁的超时时间单位 * * @return */ TimeUnit timeUnit() default TimeUnit.SECONDS;} AOP拦截器实现在AOP中我们去执行获取分布式锁和释放分布式锁的逻辑 12345678910111213141516171819202122232425262728293031323334353637@Aspect@Componentpublic class LockMethodAspect { @Autowired private RedisLockHelper redisLockHelper; @Autowired private JedisUtil jedisUtil; private Logger logger = LoggerFactory.getLogger(LockMethodAspect.class); @Around(\"@annotation(com.redis.lock.annotation.RedisLock)\") public Object around(ProceedingJoinPoint joinPoint) { Jedis jedis = jedisUtil.getJedis(); MethodSignature signature = (MethodSignature) joinPoint.getSignature(); Method method = signature.getMethod(); RedisLock redisLock = method.getAnnotation(RedisLock.class); String value = UUID.randomUUID().toString(); String key = redisLock.key(); try { final boolean islock = redisLockHelper.lock(jedis,key, value, redisLock.expire(), redisLock.timeUnit()); logger.info(\"isLock : {}\",islock); if (!islock) { logger.error(\"获取锁失败\"); throw new RuntimeException(\"获取锁失败\"); } try { return joinPoint.proceed(); } catch (Throwable throwable) { throw new RuntimeException(\"系统异常\"); } } finally { logger.info(\"释放锁\"); redisLockHelper.unlock(jedis,key, value); jedis.close(); } }} Redis实现分布式锁核心类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107@Componentpublic class RedisLockHelper { private long sleepTime = 100; /** * 直接使用setnx + expire方式获取分布式锁 * 非原子性 * * @param key * @param value * @param timeout * @return */ public boolean lock_setnx(Jedis jedis,String key, String value, int timeout) { Long result = jedis.setnx(key, value); // result = 1时，设置成功，否则设置失败 if (result == 1L) { return jedis.expire(key, timeout) == 1L; } else { return false; } } /** * 使用Lua脚本，脚本中使用setnex+expire命令进行加锁操作 * * @param jedis * @param key * @param UniqueId * @param seconds * @return */ public boolean Lock_with_lua(Jedis jedis,String key, String UniqueId, int seconds) { String lua_scripts = \"if redis.call('setnx',KEYS[1],ARGV[1]) == 1 then\" + \"redis.call('expire',KEYS[1],ARGV[2]) return 1 else return 0 end\"; List&lt;String&gt; keys = new ArrayList&lt;&gt;(); List&lt;String&gt; values = new ArrayList&lt;&gt;(); keys.add(key); values.add(UniqueId); values.add(String.valueOf(seconds)); Object result = jedis.eval(lua_scripts, keys, values); //判断是否成功 return result.equals(1L); } /** * 在Redis的2.6.12及以后中,使用 set key value [NX] [EX] 命令 * * @param key * @param value * @param timeout * @return */ public boolean lock(Jedis jedis,String key, String value, int timeout, TimeUnit timeUnit) { long seconds = timeUnit.toSeconds(timeout); return \"OK\".equals(jedis.set(key, value, \"NX\", \"EX\", seconds)); } /** * 自定义获取锁的超时时间 * * @param jedis * @param key * @param value * @param timeout * @param waitTime * @param timeUnit * @return * @throws InterruptedException */ public boolean lock_with_waitTime(Jedis jedis,String key, String value, int timeout, long waitTime,TimeUnit timeUnit) throws InterruptedException { long seconds = timeUnit.toSeconds(timeout); while (waitTime &gt;= 0) { String result = jedis.set(key, value, \"nx\", \"ex\", seconds); if (\"OK\".equals(result)) { return true; } waitTime -= sleepTime; Thread.sleep(sleepTime); } return false; } /** * 错误的解锁方法—直接删除key * * @param key */ public void unlock_with_del(Jedis jedis,String key) { jedis.del(key); } /** * 使用Lua脚本进行解锁操纵，解锁的时候验证value值 * * @param jedis * @param key * @param value * @return */ public boolean unlock(Jedis jedis,String key,String value) { String luaScript = \"if redis.call('get',KEYS[1]) == ARGV[1] then \" + \"return redis.call('del',KEYS[1]) else return 0 end\"; return jedis.eval(luaScript, Collections.singletonList(key), Collections.singletonList(value)).equals(1L); }} Controller层控制定义一个TestController来测试我们实现的分布式锁 12345678@RestControllerpublic class TestController { @RedisLock(key = \"redis_lock\") @GetMapping(\"/index\") public String index() { return \"index\"; }}","link":"/2020/07/25/RedisDistributedLock/"},{"title":"ThreadLocal","text":"简介利用synchronzed或者lock解决线程安全的问题时，会让未获取到锁的线程进行阻塞等待。线程安全问题的核心在于多个线程会对同一个临界区共享资源进行操作，那么，如果每个线程都使用自己的“共享资源”，各自用各自的，又互相不影响，让多个线程间达到隔离的状态，这样就不会出现线程安全的问题。 于是ThreadLocal应运而生，使每个线程都拥有某个变量副本，达到人手一份的效果，从而避免共享资源的竞争。 ThreadLocal的两个作用 让某个需要用到的对象在线程间隔离（每个线程都有自己的独立的对象）； 在任何方法中都可以轻松获取到该对象； 根据共享对象的生成时机不同，选择 initialValue 或 set 来保存对象 场景一：initialValue ​ 在ThreadLocal第一次get的时候把对象给初始化出来，对象的初始化时机可以由我们控制； 场景二：set ​ 如果需要保存到ThreadLocal里的对象的生成时机不由我们随意控制，例如拦截器生成的用户信息，则使用 ThreadLocal.set，以便后续使用； 源码分析 Thread ThreadLocal ThreadLocalMap 之间的关系 set()：设置在当前线程中 threadLocal 变量的值 123456789101112public void set(T value) { //1. 获取当前线程实例对象 Thread t = Thread.currentThread(); //2. 通过当前线程实例获取到ThreadLocalMap对象 ThreadLocalMap map = getMap(t); if (map != null) //3. 如果Map不为null,则以当前threadLocl实例为key,值为value进行存入 map.set(this, value); else //4.map为null,则新建ThreadLocalMap并存入value createMap(t, value);} 总结：通过当前线程对象thread获取该thread所维护的threadLocalMap,若threadLocalMap不为null,则以threadLocal实例为key,值为value的键值对存入threadLocalMap,若threadLocalMap为null的话，就新建threadLocalMap然后在以threadLocal为键，值为value的键值对存入即可。 get()：获取当前线程中threadLocal变量的值 1234567891011121314151617181920212223242526272829public T get() { //1. 获取当前线程的实例对象 Thread t = Thread.currentThread(); //2. 获取当前线程的threadLocalMap ThreadLocalMap map = getMap(t); if (map != null) { //3. 获取map中当前threadLocal实例为key的值的entry ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) { @SuppressWarnings(\"unchecked\") //4. 当前entitiy不为null的话，就返回相应的值value T result = (T)e.value; return result; } } //5. 若map为null或者entry为null的话通过该方法初始化，并返回该方法返回的value return setInitialValue();}private T setInitialValue() { T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;} 总结：通过当前线程thread实例获取到它所维护的threadLocalMap，然后以当前threadLocal实例为key获取该map中的键值对（Entry），若Entry不为null则返回Entry的value。如果获取threadLocalMap为null或者Entry为null的话，就以当前threadLocal为Key，value为null存入map后，并返回null。 initialValue() 123protected T initialValue() { return null;} 这个方法是protected修饰的也就是说继承ThreadLocal的子类可重写该方法，实现赋值为其他的初始值。 remove() 12345public void remove() { ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this);} 适用场景 每个线程需要一个独享的对象（通常是工具类，典型需要使用的类有 SimpleDateFormat 和 Random）； 重写了 initialValue() 方法； 每个线程内需要保存全局变量（例如在拦截器中获取用户信息），可以让不同方法直接使用，避免参数传递的麻烦； 用 ThreadLocal 保存一些业务内容（用户权限信息，从用户系统获取到的用户名，userID 等） 这些信息在用一个线程内相同，但是不同的线程使用的业务内容是不同的； 在线程生命周期内，都通过这个静态 ThreadLocal 实例的 get() 方法取得自己 set() 过的那个对象，避免了这个对象（例如user对象）作为参数传递的麻烦； 强调的是同一个请求内（同一个线程内）不同方法间的共享； 不需要重写 initialValue() 方法，但是必须手动调用 set() 方法 ThreadLocal带来的好处 线程安全； 不需要加锁，提高执行效率； 更高效利用内存，节省开销； ThreadLocal使得代码耦合度更低，更优雅：免去传参的繁琐，无论是场景一还是场景二，都可以在任何地方直接通过ThreadLocal拿到，再也不需要每次都传同样的参数。 可能会带来的问题内存泄漏的原因（看视频复习）ThreadLocal在ThreadLocalMap中是以一个弱引用身份被Entry中的Key引用的，因此如果ThreadLocal没有外部强引用来引用它，那么ThreadLocal会在下次JVM垃圾收集时被回收。这个时候就会出现Entry中Key已经被回收，出现一个null Key的情况，外部读取ThreadLocalMap中的元素是无法通过null Key来找到Value的。因此如果当前线程的生命周期很长，一直存在，那么其内部的ThreadLocalMap对象也一直生存下来，这些null key就存在一条强引用链的关系一直存在：Thread –&gt; ThreadLocalMap–&gt;Entry–&gt;Value，这条强引用链会导致Entry不会回收，Value也不会回收，但Entry中的Key却已经被回收的情况，造成内存泄漏。 但是JVM团队已经考虑到这样的情况，并做了一些措施来保证ThreadLocal尽量不会内存泄漏：在ThreadLocal的get()、set()、remove()方法调用的时候会清除掉线程ThreadLocalMap中所有Entry中Key为null的Value，并将整个Entry设置为null，利于下次内存回收。 1234567891011121314151617181920212223242526272829303132333435private int expungeStaleEntry(int staleSlot) { Entry[] tab = table; int len = tab.length; // expunge entry at staleSlot tab[staleSlot].value = null; tab[staleSlot] = null; size--; // Rehash until we encounter null Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) { ThreadLocal&lt;?&gt; k = e.get(); if (k == null) { e.value = null; tab[i] = null; size--; } else { int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) { tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; } } } return i; } https://blog.csdn.net/ThinkWon/article/details/102508381","link":"/2020/07/19/ThreadLocal/"},{"title":"ThreadPool","text":"线程池为什么使用线程池 创建/销毁线程需要消耗系统资源，线程池可以复用已创建的线程； 控制并发的数量。并发数量过多，可能会导致资源消耗过多，从而造成服务器崩溃。（主要原因）； 可以对线程做统一管理； 原理 ThreadPoolExecutor 四种构造方法 12345678910111213141516171819202122232425262728293031// 五个参数的构造函数public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue)// 六个参数的构造函数-1public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory)// 六个参数的构造函数-2public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler)// 七个参数的构造函数public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) int corePoolSize：该线程池中核心线程数最大值； 核心线程：线程池中有两类线程，核心线程和非核心线程。核心线程默认情况下会一直存在于线程池中，即使这个核心线程什么都不干。 int maximumPoolSize：该线程池中线程总数最大值； long keepAliveTime：非核心线程闲置超时时长； 非核心线程如果处于闲置状态超过该值，就会被销毁。如果设置allowCoreThreadTimeOut(true)，则会也作用于核心线程。 TimeUnit unit：keepAliveTime的单位。 TimeUnit是一个枚举类型 ，包括以下属性： NANOSECONDS ： 1微毫秒 = 1微秒 / 1000 MICROSECONDS ： 1微秒 = 1毫秒 / 1000 MILLISECONDS ： 1毫秒 = 1秒 /1000 SECONDS ： 秒 MINUTES ： 分 HOURS ： 小时 DAYS ： 天 BlockingQueue workQueue：阻塞队列，维护着等待执行的Runnable任务对象； ThreadFactory threadFactory：创建线程的工厂，用于批量创建线程，统一在创建线程时设置一些参数，如是否守护线程、线程的优先级等。如果不指定，会新建一个默认的线程工厂。 123456789101112131415161718192021222324252627/** * The default thread factory */static class DefaultThreadFactory implements ThreadFactory { private static final AtomicInteger poolNumber = new AtomicInteger(1); private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private final String namePrefix; DefaultThreadFactory() { SecurityManager s = System.getSecurityManager(); group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = \"pool-\" + poolNumber.getAndIncrement() + \"-thread-\"; } public Thread newThread(Runnable r) { Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; }} RejectedExecutionHandler handler：拒绝处理策略，线程数量大于最大线程数就会采用拒绝处理策略，四种： ThreadPoolExecutor.AbortPolicy：默认拒绝处理策略，丢弃任务并抛出RejectedExecutionException异常； ThreadPoolExecutor.DiscardPolicy：丢弃新来的任务，但是不抛出异常； ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列头部（最旧的）的任务，然后重新尝试执行程序（如果再次失败，重复此过程）； ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务； 线程池状态线程池本身有一个调度线程，这个线程就是用于管理布控整个线程池里的各种任务和事务，例如创建线程、销毁线程、任务队列管理、线程队列管理等等，故线程池也有自己的状态。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/** * The main pool control state, ctl, is an atomic integer packing * two conceptual fields * workerCount, indicating the effective number of threads * runState, indicating whether running, shutting down etc * * In order to pack them into one int, we limit workerCount to * (2^29)-1 (about 500 million) threads rather than (2^31)-1 (2 * billion) otherwise representable. If this is ever an issue in * the future, the variable can be changed to be an AtomicLong, * and the shift/mask constants below adjusted. But until the need * arises, this code is a bit faster and simpler using an int. * * The workerCount is the number of workers that have been * permitted to start and not permitted to stop. The value may be * transiently different from the actual number of live threads, * for example when a ThreadFactory fails to create a thread when * asked, and when exiting threads are still performing * bookkeeping before terminating. The user-visible pool size is * reported as the current size of the workers set. * * The runState provides the main lifecycle control, taking on values: * * RUNNING: Accept new tasks and process queued tasks * SHUTDOWN: Don't accept new tasks, but process queued tasks * STOP: Don't accept new tasks, don't process queued tasks, * and interrupt in-progress tasks * TIDYING: All tasks have terminated, workerCount is zero, * the thread transitioning to state TIDYING * will run the terminated() hook method * TERMINATED: terminated() has completed * * The numerical order among these values matters, to allow * ordered comparisons. The runState monotonically increases over * time, but need not hit each state. The transitions are: * * RUNNING -&gt; SHUTDOWN * On invocation of shutdown(), perhaps implicitly in finalize() * (RUNNING or SHUTDOWN) -&gt; STOP * On invocation of shutdownNow() * SHUTDOWN -&gt; TIDYING * When both queue and pool are empty * STOP -&gt; TIDYING * When pool is empty * TIDYING -&gt; TERMINATED * When the terminated() hook method has completed * * Threads waiting in awaitTermination() will return when the * state reaches TERMINATED. * * Detecting the transition from SHUTDOWN to TIDYING is less * straightforward than you'd like because the queue may become * empty after non-empty and vice versa during SHUTDOWN state, but * we can only terminate if, after seeing that it is empty, we see * that workerCount is 0 (which sometimes entails a recheck -- see * below). */private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3;private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1; // runState is stored in the high-order bitsprivate static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; 线程池创建后处于RUNNING状态； 调用shutdown()方法后处于SHUTDOWN状态，线程池不能接受新的任务，清除一些空闲worker，会等待阻塞队列的任务完成；（SHUTDOWN：不接受新任务，但处理排队任务） 调用shutdownNow()方法后处于STOP状态，线程池不能接受新的任务，中断所有线程，阻塞队列中没有被执行的任务全部丢弃。此时，poolsize=0,阻塞队列的size也为0；（STOP：不接受新任务，也不处理排队任务，并中断正在执行的任务） 当所有的任务已终止，ctl记录的”任务数量”为0，线程池会变为TIDYING状态。接着会执行terminated()钩子方法； ThreadPoolExecutor中有一个控制状态的属性叫ctl，它是一个AtomicInteger类型的变量。 线程池处在TIDYING状态时，执行完terminated()方法之后，就会由 TIDYING -&gt; TERMINATED， 线程池被设置为TERMINATED状态； 线程池的任务处理流程123456789101112131415161718192021222324252627282930313233343536373839404142// JDK 1.8// 执行命令，其中命令（下面称任务）对象是Runnable的实例public void execute(Runnable command) { // 判断命令（任务）对象非空 if (command == null) throw new NullPointerException(); // 获取ctl的值 int c = ctl.get(); // 判断如果当前工作线程数小于核心线程数，则创建新的核心线程并且执行传入的任务 if (workerCountOf(c) &lt; corePoolSize) { if (addWorker(command, true)) // 如果创建新的核心线程成功则直接返回 return; // 这里说明创建核心线程失败，需要更新ctl的临时变量c c = ctl.get(); } // 如果不小于corePoolSize，则将任务添加到workQueue队列。 // 判断线程池是否处于运行中状态，同时尝试用非阻塞方法向任务队列放入任务（放入任务失败返回false） if (isRunning(c) &amp;&amp; workQueue.offer(command)) { int recheck = ctl.get(); // 这里是向任务队列投放任务成功，对线程池的运行中状态做二次检查 // 如果线程池二次检查状态是非运行中状态，则从任务队列移除当前的任务调用拒绝策略处理之（也就是移除前面成功入队的任务实例） if (! isRunning(recheck) &amp;&amp; remove(command)) // 调用拒绝策略处理任务 - 返回 reject(command); // 线程池处于running状态，但是没有线程，则创建线程 // 如果当前工作线程数量为0，则创建一个非核心线程并且传入的任务对象为null - 返回 // 也就是创建的非核心线程不会马上运行，而是等待获取任务队列的任务去执行 // 如果前工作线程数量不为0，原来应该是最后的else分支，但是可以什么也不做，因为任务已经成功入队列，总会有合适的时机分配其他空闲线程去执行它 else if (workerCountOf(recheck) == 0) addWorker(null, false); } // 走到这里说明有以下的前提： // 0、线程池中的工作线程总数已经大于等于corePoolSize（简单来说就是核心线程已经全部懒创建完毕） // 1、线程池可能不是RUNNING状态 // 2、线程池可能是RUNNING状态同时任务队列已经满了 // 如果放入workQueue失败，则创建非核心线程执行任务， // 如果这时创建非核心线程失败(当前线程总数不小于maximumPoolSize时)，就会执行拒绝策略。 else if (!addWorker(command, false)) // 调用拒绝策略处理任务 - 返回 reject(command);} 为什么要二次检查线程池的状态? 在多线程的环境下，线程池的状态是时刻发生变化的。很有可能刚获取线程池状态后线程池状态就改变了。判断是否将command加入workqueue是线程池之前的状态。倘若没有二次检查，万一线程池处于非RUNNING状态（在多线程环境下很有可能发生），那么command永远不会执行。 整体流程： 线程总数量小于corePoolSize，无论线程是否空闲，都会直接创建核心线程执行任务（注意，这一步需要获得全局锁）； 线程总数量大于等于corePoolSize，判断线程池是否处于运行中状态，同时尝试用非阻塞方法向任务队列放入任务，这里会二次检查线程池运行状态，如果当前工作线程数量为0，则创建一个非核心线程并且传入的任务对象为null； 如果缓存队列满了，则会尝试创建非核心线程传入任务实例执行（注意这一步需要获得全局锁）； 如果创建非核心线程失败，此时需要拒绝执行任务，调用拒绝策略处理任务； ThreadPoolExecutor如何做到线程复用的？123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596/** * Checks if a new worker can be added with respect to current * pool state and the given bound (either core or maximum). If so, * the worker count is adjusted accordingly, and, if possible, a * new worker is created and started, running firstTask as its * first task. This method returns false if the pool is stopped or * eligible to shut down. It also returns false if the thread * factory fails to create a thread when asked. If the thread * creation fails, either due to the thread factory returning * null, or due to an exception (typically OutOfMemoryError in * Thread.start()), we roll back cleanly. * * @param firstTask the task the new thread should run first (or * null if none). Workers are created with an initial first task * (in method execute()) to bypass queuing when there are fewer * than corePoolSize threads (in which case we always start one), * or when the queue is full (in which case we must bypass queue). * Initially idle threads are usually created via * prestartCoreThread or to replace other dying workers. * * @param core if true use corePoolSize as bound, else * maximumPoolSize. (A boolean indicator is used here rather than a * value to ensure reads of fresh values after checking other pool * state). * @return true if successful */private boolean addWorker(Runnable firstTask, boolean core) { retry: for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) { int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop } } boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try { // 创建一个worker对象 w = new Worker(firstTask); // 实例化一个Thread对象 final Thread t = w.thread; if (t != null) { // 线程池全局锁 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) { if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; } } finally { mainLock.unlock(); } if (workerAdded) { // 启动这个线程 t.start(); workerStarted = true; } } } finally { if (! workerStarted) addWorkerFailed(w); } return workerStarted;} worker类部分源码： 12345678910111213141516// Worker类部分源码private final class Worker extends AbstractQueuedSynchronizer implements Runnable{ final Thread thread; Runnable firstTask; Worker(Runnable firstTask) { setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); } public void run() { runWorker(this); } //其余代码略...} Worker类实现了Runnable接口，所以Worker也是一个线程任务。在构造方法中，创建了一个线程，线程的任务就是自己。故addWorker方法调用addWorker方法源码下半部分中的第4步t.start，会触发Worker类的run方法被JVM调用。 常见的四种线程池 1）newCachedThreadPool：它是一个可以无限扩大的线程池 12345public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());} 它比较适合处理执行时间比较短的任务； corePoolSize为0，maxPoolSize为无限大，意味着线程数量可以无限大，keepAliveTime为60S，意味着线程空闲时间超过60S就会被回收； 采用SynchronousQueue装等待的任务，这个阻塞队列没有存储空间，这意味着只要有请求到来，就必须要找到一条工作线程处理他，如果当前没有空闲的线程，那么就会再创建一条新的线程； 存在的问题：无界线程池，具有自动回收多余线程的功能。弊端在于第二个参数maxPoolSize被设置为Integer.MAX_VALUE，这可能会创建数量非常多的线程，甚至导致OOM。 2）newFixedThreadPool：它是一种固定大小的线程池 12345public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());} corePoolSize和maxPoolSize都为用户设定的线程数量nThreads； keepAliveTime为0，意味着一旦有多余的空闲线程，就会被立即停止掉；但这里keepAliveTime无效； 阻塞队列采用了LinkedBlockingQueue，它是一个无界队列，因此永远不可能拒绝任务；故如果核心线程空闲，则交给核心线程处理；如果核心线程不空闲，则入列等待，直到核心线程空闲。 存在的问题：由于传入的LinkedBlockingQueue是没有容量上限的，所以当请求数越来越多，并且无法及时处理完毕的时候，即请求堆积的时候，会容易造成占用大量的内存，可能会导致OOM。 与CachedThreadPool的区别： 因为 corePoolSize == maximumPoolSize ，所以FixedThreadPool只会创建核心线程。 而CachedThreadPool因为corePoolSize=0，所以只会创建非核心线程。 在 getTask() 方法，如果队列里没有任务可取，线程会一直阻塞在 LinkedBlockingQueue.take() ，线程不会被回收。 CachedThreadPool会在60s后收回。 由于线程不会被回收，会一直卡在阻塞，所以没有任务的情况下， FixedThreadPool占用资源更多。 都几乎不会触发拒绝策略，但是原理不同。FixedThreadPool是因为阻塞队列可以很大（最大为Integer最大值），故几乎不会触发拒绝策略；CachedThreadPool是因为线程池很大（最大为Integer最大值），几乎不会导致线程数量大于最大线程数，故几乎不会触发拒绝策略。 3）newSingleThreadExecutor：有且仅有一个核心线程 123456public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));} 有且仅有一个核心线程（ corePoolSize == maximumPoolSize=1），使用了LinkedBlockingQueue（容量很大），所以，不会创建非核心线程。所有任务按照先来先执行的顺序执行。 存在的问题：由于传入的LinkedBlockingQueue是没有容量上限的，所以如果这个唯一的线程不空闲，那么新来的任务会堆积在任务队列里等待执行，会容易造成占用大量的内存，可能会导致OOM。 4）newScheduledThreadPool：可调度的线程池 12345678910public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) { return new ScheduledThreadPoolExecutor(corePoolSize);}//ScheduledThreadPoolExecutor():public ScheduledThreadPoolExecutor(int corePoolSize) { super(corePoolSize, Integer.MAX_VALUE, DEFAULT_KEEPALIVE_MILLIS, MILLISECONDS, new DelayedWorkQueue());} 创建一个定长线程池，支持定时及周期性任务执行。 线程池里的线程数量设定为多少比较合适？ CPU密集型（加密，计算hash等）：最佳线程数为CPU核心数的1-2倍左右； 耗时IO型（读写数据库、文件、网络读写等）：最佳线程数一般会大于CPU核心数很多倍，以JVM线程监控显示繁忙情况为依据，保证线程空闲可以衔接上。 参考Brain Goetz推荐的计算方法； 线程数 = CPU核心数 * （1 + 平均等待时间 / 平均工作时间） 或者进行压测，根据压测结果确定线程数； 阻塞队列场景BlockingQueue一般用于生产者-消费者模式，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。BlockingQueue就是存放元素的容器。 操作方法 方法\\处理方式 抛出异常 返回特殊值 一直阻塞 超时退出 插入方法 add(e) offer(e) put(e) offer(e,time,unit) 移除方法 remove() poll() take() poll(time,unit) 检查方法 element() peek() - - 抛出异常：如果试图的操作无法立即执行，抛异常。当阻塞队列满时候，再往队列里插入元素，会抛出IllegalStateException(“Queue full”)异常。当队列为空时，从队列里获取元素时会抛出NoSuchElementException异常 。 返回特殊值：如果试图的操作无法立即执行，返回一个特殊值，通常是true / false。 一直阻塞：如果试图的操作无法立即执行，则一直阻塞或者响应中断。 超时退出：如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行，但等待时间不会超过给定值。返回一个特定值以告知该操作是否成功，通常是 true / false。 注意之处 不能往阻塞队列中插入null,会抛出空指针异常。 可以访问阻塞队列中的任意元素，调用remove(o)可以将队列之中的特定对象移除，但并不高效，尽量避免使用。 实现类 1）ArrayBlockingQueue 有界阻塞队列，内部结构是数组，故具有数组的特性。 123public ArrayBlockingQueue(int capacity, boolean fair){ //..省略代码} 可以初始化队列大小， 且一旦初始化不能改变。构造方法中的fair表示控制对象的内部锁是否采用公平锁，默认是非公平锁。 2）LinkedBlockingQueue 有界阻塞队列，内部结构是链表，具有链表的特性。默认队列的大小是Integer.MAX_VALUE，也可以指定大小。此队列按照先进先出的原则对元素进行排序。 3）DelayQueue DelayQueue是一个没有大小限制的队列，因此往队列中插入数据的操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻塞。 注入其中的元素必须实现 java.util.concurrent.Delayed 接口。该队列中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素。 4）PriorityBlockingQueue 基于优先级的无界阻塞队列（优先级的判断通过构造函数传入的Compator对象来决定），内部控制线程同步的锁采用的是公平锁。 PriorityBlockingQueue不会阻塞数据生产者（因为队列是无界的），而只会在没有可消费的数据时，阻塞数据的消费者。因此使用的时候要特别注意，生产者生产数据的速度绝对不能快于消费者消费数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。对于使用默认大小的LinkedBlockingQueue也是一样的。 5）SynchronousQueue 这个队列比较特殊，没有任何内部容量，甚至连一个队列的容量都没有。并且每个put必须等待一个take，反之亦然。 需要区别容量为1的ArrayBlockingQueue、LinkedBlockingQueue。 以下方法的返回值，可以帮助理解这个队列： iterator() 永远返回空，因为里面没有东西； peek() 永远返回null； put() 往queue放进去一个element以后就一直wait直到有其他thread进来把这个element取走； offer() 往queue里放一个element后立即返回，如果碰巧这个element被另一个thread取走了，offer方法返回true，认为offer成功；否则返回false； take() 取出并且remove掉queue里的element，取不到东西他会一直等； poll() 取出并且remove掉queue里的element，只有到碰巧另外一个线程正在往queue里offer数据或者put数据的时候，该方法才会取到东西。否则立即返回null； isEmpty() 永远返回true； remove()&amp;removeAll() 永远返回false； 源码分析 构造器 对同一个锁（lock）初始化了两个监视器，分别是notEmpty和notFull。这两个监视器的作用目前可以简单理解为标记分组，当该线程是put操作时，给他加上监视器notFull,标记这个线程是一个生产者；当线程是take操作时，给他加上监视器notEmpty，标记这个线程是消费者。 123456789101112131415161718192021//数据元素数组final Object[] items;//下一个待取出元素索引int takeIndex;//下一个待添加元素索引int putIndex;//元素个数int count;//内部锁final ReentrantLock lock;//消费者监视器private final Condition notEmpty;//生产者监视器private final Condition notFull; public ArrayBlockingQueue(int capacity, boolean fair) { //..省略其他代码 lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition();} put源码 12345678910111213141516171819202122232425262728public void put(E e) throws InterruptedException { checkNotNull(e); final ReentrantLock lock = this.lock; // 1.自旋拿锁 lock.lockInterruptibly(); try { // 2.判断队列是否满了 while (count == items.length) // 2.1如果满了，阻塞该线程，并标记为notFull线程， // 等待notFull的唤醒，唤醒之后继续执行while循环。 notFull.await(); // 3.如果没有满，则进入队列 enqueue(e); } finally { lock.unlock(); }}private void enqueue(E x) { // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; final Object[] items = this.items; items[putIndex] = x; if (++putIndex == items.length) putIndex = 0; count++; // 4 唤醒一个等待的线程 notEmpty.signal();} 所有执行put操作的线程竞争lock锁，拿到了lock锁的线程进入下一步，没有拿到lock锁的线程自旋竞争锁。 判断阻塞队列是否满了，如果满了，则调用await方法阻塞这个线程，并标记为notFull（生产者）线程，同时释放lock锁,等待被消费者线程唤醒。 如果没有满，则调用enqueue方法将元素put进阻塞队列。注意这一步的线程还有一种情况是第二步中阻塞的线程被唤醒且又拿到了lock锁的线程。 唤醒一个标记为notEmpty（消费者）的线程。 take源码 1234567891011121314151617181920212223242526public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == 0) notEmpty.await(); return dequeue(); } finally { lock.unlock(); }}private E dequeue() { // assert lock.getHoldCount() == 1; // assert items[takeIndex] != null; final Object[] items = this.items; @SuppressWarnings(\"unchecked\") E x = (E) items[takeIndex]; items[takeIndex] = null; if (++takeIndex == items.length) takeIndex = 0; count--; if (itrs != null) itrs.elementDequeued(); notFull.signal(); return x;} take操作和put操作的流程是类似的，总结一下take操作的流程： 所有执行take操作的线程竞争lock锁，拿到了lock锁的线程进入下一步，没有拿到lock锁的线程自旋竞争锁。 判断阻塞队列是否为空，如果是空，则调用await方法阻塞这个线程，并标记为notEmpty（消费者）线程，同时释放lock锁,等待被生产者线程唤醒。 如果没有空，则调用dequeue方法。注意这一步的线程还有一种情况是第二步中阻塞的线程被唤醒且又拿到了lock锁的线程。 唤醒一个标记为notFull（生产者）的线程。 应用场景 生产者-消费者模式 线程池中","link":"/2020/07/15/ThreadPool/"},{"title":"VariousLock","text":"","link":"/2020/07/15/VariousLock/"},{"title":"basicconcurrency","text":"进程和线程的区别 进程是一个独立的运行环境，而线程是在进程中执行的一个任务。他们两个本质的区别是是否单独占有内存地址空间及其它系统资源（比如I/O）： 进程单独占有一定的内存地址空间，所以进程间存在内存隔离，数据是分开的，数据共享复杂但是同步简单，各个进程之间互不干扰；而线程共享所属进程占有的内存地址空间和资源，数据共享简单，但是同步复杂。 进程单独占有一定的内存地址空间，一个进程出现问题不会影响其他进程，不影响主程序的稳定性，可靠性高；一个线程崩溃可能影响整个程序的稳定性，可靠性较低。 进程单独占有一定的内存地址空间，进程的创建和销毁不仅需要保存寄存器和栈信息，还需要资源的分配回收以及页调度，开销较大；线程只需要保存寄存器和栈信息，开销较小。 另外一个重要区别是，进程是操作系统进行资源分配的基本单位，而线程是操作系统进行调度的基本单位，即CPU分配时间的单位 。 上下文切换 CPU为每个进程分配一个时间段，称作它的时间片。如果在时间片结束时进程还在运行，则暂停这个进程的运行，并且CPU分配给另一个进程（这个过程叫做上下文切换）。如果进程在时间片结束前阻塞或结束，则CPU立即进行切换，不用等待时间片用完。 上下文切换（有时也称做进程切换或任务切换）是指 CPU 从一个进程（或线程）切换到另一个进程（或线程）。上下文是指某一时间点 CPU 寄存器和程序计数器的内容。 CPU通过为每个线程分配CPU时间片来实现多线程机制。CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。 但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这个任务的状态。所以任务从保存到再加载的过程就是一次上下文切换。 寄存器是cpu内部的少量的速度很快的闪存，通常存储和访问计算过程的中间值提高计算机程序的运行速度。 程序计数器是一个专用的寄存器，用于表明指令序列中 CPU 正在执行的位置，存的值为正在执行的指令的位置或者下一个将要被执行的指令的位置，具体实现依赖于特定的系统。 举例说明 线程A - B 1.先挂起线程A，将其在cpu中的状态保存在内存中。 2.在内存中检索下一个线程B的上下文并将其在 CPU 的寄存器中恢复,执行B线程。 3.当B执行完，根据程序计数器中指向的位置恢复线程A。 实现多线程 我们在程序里面调用了start()方法后，虚拟机会先为我们创建一个线程，然后等到这个线程第一次得到时间片时再调用run()方法。 1.1 继承Thread类或者实现Runnable接口这两种方式，它们之间有什么优劣呢？ 由于Java“单继承，多实现”的特性，Runnable接口使用起来比Thread更灵活；Runnable接口出现更符合面向对象，将线程单独进行对象的封装；Runnable接口出现，降低了线程对象和线程任务的耦合性；如果使用线程时不需要使用Thread类的诸多方法，显然使用Runnable接口更为轻量；所以，我们通常优先使用“实现Runnable接口”这种方式来自定义线程类。 1.2 同时使用两种方法： 12345678public static void main(String[] args) { new Thread(() -&gt; System.out.println(\"我来自Runnable\")) { @Override public void run() { System.out.println(\"我来自Thread\"); } }.start(); } 输出：我来自Thread 线程的状态 RUNNABLE： 1234567/** * Thread state for a runnable thread. A thread in the runnable * state is executing in the Java virtual machine but it may * be waiting for other resources from the operating system * such as processor. */RUNNABLE, 处于RUNNABLE状态的线程在Java虚拟机中运行，也有可能在等待其他系统资源（比如I/O）。 Java线程的RUNNABLE状态其实是包括了传统操作系统线程的ready和running两个状态的。 线程的生命周期 1234567891011121314151617181920212223242526272829303132public synchronized void start() { /** * This method is not invoked for the main method thread or \"system\" * group threads created/set up by the VM. Any new functionality added * to this method in the future may have to also be added to the VM. * * A zero status value corresponds to state \"NEW\". */ if (threadStatus != 0) throw new IllegalThreadStateException(); /* Notify the group that this thread is about to be started * so that it can be added to the group's list of threads * and the group's unstarted count can be decremented. */ group.add(this); boolean started = false; try { start0(); started = true; } finally { try { // 若线程启动失败，从线程组里移除该线程 if (!started) { group.threadStartFailed(this); } } catch (Throwable ignore) { /* do nothing. If start0 threw a Throwable then it will be passed up the call stack */ } }} 如何正确停止线程 线程中断机制是一种协作机制。通过中断操作并不能直接终止一个线程，而是通知需要被中断的线程自行处理。 Thread.interrupt()：中断线程。这里的中断线程并不会立即停止线程，而是设置线程的中断状态为true（默认是flase）； Thread.interrupted()：测试当前线程是否被中断。线程的中断状态受这个方法的影响，意思是调用一次使线程中断状态设置为true，连续调用两次会使得这个线程的中断状态重新转为false； Thread.isInterrupted()：测试当前线程是否被中断。与上面方法不同的是调用这个方法并不会影响线程的中断状态； 原理介绍：使用interrupt来通知，而不是强制 解读：想要停止线程，其实是如何正确的用interrupt通知那个线程，以及被停止的线程如何配合。 使用interrupt 普通情况下停止线程 123456789101112131415161718192021public class RightWayStopThreadWithoutSleep implements Runnable { public static void main(String[] args) throws InterruptedException { Thread thread = new Thread(new RightWayStopThreadWithoutSleep()); thread.start(); Thread.sleep(1000); thread.interrupt(); } @Override public void run() { int num = 0; while (!Thread.currentThread().isInterrupted() &amp;&amp; num &lt;= Integer.MAX_VALUE / 2) { if (num % 10000 == 0) { System.out.println(num + \"是10000的倍数\"); } num++; } System.out.println(\"任务运行结束了\"); }} 线程可能被阻塞的情况下被停止 12345678910111213141516171819202122232425262728293031public class RightWayStopThreadWithSleep { public static void main(String[] args) throws InterruptedException { Runnable runnable = () -&gt; { int num = 0; try { while (num &lt; 300 &amp;&amp; !Thread.currentThread().isInterrupted()) { if (num % 100 == 0) { System.out.println(num + \"是100的倍数\"); } num++; } Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } }; Thread thread = new Thread(runnable); thread.start(); Thread.sleep(500); thread.interrupt(); }}/**0是100的倍数100是100的倍数200是100的倍数java.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at threadcoreknowledge.stopthreads.RightWayStopThreadWithSleep.lambda$main$0(RightWayStopThreadWithSleep.java:21) at java.lang.Thread.run(Thread.java:748)*/ 如果线程在每次迭代后被阻塞 如果在执行过程中，每次循环都会调用sleep或wait等方法，那么不需要每次迭代都检查是否已中断。 1234567891011121314151617181920212223public class RightWayStopThreadWithSleepEveryLoop { public static void main(String[] args) throws InterruptedException { Runnable runnable = () -&gt; { int num = 0; try { // 不需要做是否中断的检测 while (num &lt; 10000) { if (num % 100 == 0) { System.out.println(num + \"是100的倍数\"); } num++; Thread.sleep(10); } } catch (InterruptedException e) { e.printStackTrace(); } }; Thread thread = new Thread(runnable); thread.start(); Thread.sleep(5000); thread.interrupt(); }} 如果while里面放try/catch，会导致中断失效 因为sleep会清除中断信号，将中断标记位设置成 false（源码分析待补全） 12345678910111213141516171819202122public class CantInterrupt { public static void main(String[] args) throws InterruptedException { Runnable runnable = () -&gt; { int num = 0; while (num &lt; 10000 &amp;&amp; !Thread.currentThread().isInterrupted()) { if (num % 100 == 0) { System.out.println(num + \"是100的倍数\"); } num++; try { Thread.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } } }; Thread thread = new Thread(runnable); thread.start(); Thread.sleep(5000); thread.interrupt(); }} 实际开发中的两种最佳实践 不应屏蔽中断 优先选择：传递中断 catch了InterruptException之后的优先选择：在方法签名中抛出异常，那么在run()就会强制try/catch 1234567891011121314151617181920212223242526public class RightWaySropThreadInProd1 implements Runnable { public static void main(String[] args) throws InterruptedException { Thread thread = new Thread(new RightWaySropThreadInProd1()); thread.start(); Thread.sleep(1000); thread.interrupt(); } @Override public void run() { while (true) { System.out.println(\"go\"); try { throwInMethod(); } catch (InterruptedException e) { // 保存日志，停止程序 System.out.println(\"保存日志\"); e.printStackTrace(); } } } private void throwInMethod() throws InterruptedException { Thread.sleep(1000); }} 不想或无法传递：恢复中断 在catch子语句中调用Thread.currentThread().interrupt()来恢复设置中断状态，以便在后续的执行中，依然能够检查到刚才发生了中断。（使得其他代码有办法知道它发生了中断） 12345678910111213141516171819202122232425262728public class RightWaySropThreadInProd2 implements Runnable { public static void main(String[] args) throws InterruptedException { Thread thread = new Thread(new RightWaySropThreadInProd2()); thread.start(); Thread.sleep(1000); thread.interrupt(); } @Override public void run() { while (true) { if (Thread.currentThread().isInterrupted()) { System.out.println(\"程序运行结束\"); break; } reInterrupt(); } } private void reInterrupt() { try { Thread.sleep(1000); } catch (InterruptedException e) { Thread.currentThread().interrupt(); e.printStackTrace(); } }} 响应中断的方法总结列表 Object.wait()/wait(long)/wait(long, int) Thread.sleep(long)/sleep(long, int) Thread.join()/join(long)/join(long, int) java.util.cocurrent.BlockingQueue.take()/put(E) java.util.cocurrent.locks.Lock.lockInterruptibly() java.util.cocurrent.CountDownLatch.await() java.util.cocurrent.CyclicBarrier.await() java.util.cocurrent.Exchanger.exchange(V) java.nio.channels.InterruptibleChannel相关方法 java.nio.channels.Selector相关方法 错误的停止方法 被弃用的stop，suspend，resume方法（待补全） stop() 弃用原因： 原因1：即刻停止run()方法中剩余的全部工作，包括在catch或finally语句中，并抛出ThreadDeath异常(通常情况下此异常不需要显示的捕获)，因此可能会导致一些清理性的工作的得不到完成，如文件，数据库等的关闭； 原因2：会立即释放该线程所持有的所有的锁，导致数据得不到同步的处理，出现数据不一致的问题； suspend() resume()弃用原因 suspend()和resume()必须要成对出现，否则非常容易发生死锁； 不推荐使用suspend()去挂起线程的原因，是因为suspend()在导致线程暂停的同时，并不会去释放任何锁资源。其他线程都无法访问被它占用的锁。直到对应的线程执行resume()方法后，被挂起的线程才能继续，从而其它被阻塞在这个锁的线程才可以继续执行。 如果一个线程在resume目标线程之前尝试持有这个重要的系统资源锁再去resume目标线程，这两条线程就相互死锁了，也就冻结线程。 用volatile设置boolean标记位 原因：如果线程发生阻塞了，它将无法执行判断标识位的代码，阻塞无法收到停止线程的通知。线程依然不能停止。 停止线程相关重要函数解析（待补全） interrupt方法 1234567891011121314public void interrupt() { if (this != Thread.currentThread()) checkAccess(); synchronized (blockerLock) { Interruptible b = blocker; if (b != null) { interrupt0(); // Just to set the interrupt flag b.interrupt(this); return; } } interrupt0();} 判断是否已被中断相关方法 static boolean interrupted() boolean isInterrupted() Thread.interrupted()的目的对象 线程的各个属性 线程的异常 代码举例： 123456789101112131415public class MyUncaughtExceptionHandler implements Thread.UncaughtExceptionHandler { private String name; public MyUncaughtExceptionHandler(String name) { this.name = name; } @Override public void uncaughtException(Thread t, Throwable e) { Logger logger = Logger.getAnonymousLogger(); logger.log(Level.WARNING, \"线程异常，终止啦\" + t.getName()); System.out.println(name + \"捕获了异常\" + t.getName() + \"异常\"); }} 123456789101112131415161718public class UseOwnUncaughtExceptionHandler implements Runnable { public static void main(String[] args) throws InterruptedException { Thread.setDefaultUncaughtExceptionHandler(new MyUncaughtExceptionHandler(\"捕获器1\")); new Thread(new UseOwnUncaughtExceptionHandler(), \"MyThread-1\").start(); Thread.sleep(300); new Thread(new UseOwnUncaughtExceptionHandler(), \"MyThread-2\").start(); Thread.sleep(300); new Thread(new UseOwnUncaughtExceptionHandler(), \"MyThread-3\").start(); Thread.sleep(300); new Thread(new UseOwnUncaughtExceptionHandler(), \"MyThread-4\").start(); } @Override public void run() { throw new RuntimeException(); }} 输出： 1234567891011121314七月 11, 2020 4:02:09 下午 threadcoreknowledge.uncaughtexception.MyUncaughtExceptionHandler uncaughtException警告: 线程异常，终止啦MyThread-1捕获器1捕获了异常MyThread-1异常七月 11, 2020 4:02:09 下午 threadcoreknowledge.uncaughtexception.MyUncaughtExceptionHandler uncaughtException警告: 线程异常，终止啦MyThread-2捕获器1捕获了异常MyThread-2异常七月 11, 2020 4:02:09 下午 threadcoreknowledge.uncaughtexception.MyUncaughtExceptionHandler uncaughtException警告: 线程异常，终止啦MyThread-3捕获器1捕获了异常MyThread-3异常七月 11, 2020 4:02:10 下午 threadcoreknowledge.uncaughtexception.MyUncaughtExceptionHandler uncaughtException警告: 线程异常，终止啦MyThread-4捕获器1捕获了异常MyThread-4异常Process finished with exit code 0 Thread及Object中线程相关的重要方法 类 方法名 简介 Thread sleep相关 相关，指重写的方法 join 等待其他线程执行完毕 yield相关 放弃以获取到的CPU资源 currentThread 获取当前执行线程的引用 start，run相关 启动线程相关 interrupt相关 中断线程 stop()，suspend()，resume()相关 已废弃 Object wait/notify/notifyAll相关 让线程暂时休眠或唤醒 currentThread()：静态方法，返回对当前正在执行的线程对象的引用；start()：开始执行线程的方法，java虚拟机会调用线程内的run()方法；yield()：yield在英语里有放弃的意思，同样，这里的yield()指的是当前线程愿意让出对当前处理器的占用。这里需要注意的是，就算当前线程调用了yield()方法，程序在调度的时候，也还有可能继续运行这个线程的；sleep()：静态方法，使当前线程睡眠一段时间；join()：使当前线程等待另一个线程执行完毕之后再继续执行，内部调用的是Object类的wait方法实现的；","link":"/2020/07/11/basicconcurrency/"},{"title":"jvm","text":"Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的高墙，墙外面的人想进去，墙里面的人却想出来。 JVM运行时数据区","link":"/2020/06/26/jvm/"},{"title":"springframework","text":"项目导入IDEA 环境：Windows，JDK8，Gradle 6.5.1，IDEA 2020.1.3 进入 https://github.com/spring-projects/spring-framework，选择版本5.2.X，下载zip或clone到本地； 编辑项目目录下的build.gradle，全局搜索allprojects，编辑其repositories属性，配置阿里云镜像，如下： 123456repositories { maven { url 'http://maven.aliyun.com/nexus/content/groups/public/' } maven{ url 'http://maven.aliyun.com/nexus/content/repositories/jcenter'} mavenCentral() maven { url \"https://repo.spring.io/libs-spring-framework-build\" }} 进入项目根目录下，预编译spring-oxm，在命令行中执行： 1gradlew :spring-oxm:compileTestJava (需耐心等待3-5分钟左右…) 成功后打印BUILD SUCCESSFUL 导入项目至idea； 移除spring-aspects模块； 阅读reference文档 GA：General Availability，官方正式发布的稳定版本（RELEASE，Stable，Final） RC：Release Candidate，发行候选版本，基本不再加入新的功能 Alpha：内部测试版本，bug较多，功能不全 Beta：公开测试版本，比Alpha晚些，还会加功能，修bug M：Milestone，开发期发行版本，边开发边发行 单一职责原则 门面模式 facade pattern 子系统的外部与其内部的通信必须通过统一的对象进行 提供一个高层次的接口，使得子系统更易于使用 适配器模式 泛型 让数据类型变得参数化 定义泛型时，对应的数据类型是不确定的； 泛型方法被调用时，会指定具体类型； 核心目标：解决容器类型在编译时安全检查的问题 泛型类 泛型的参数不支持基本类型 泛型相关的信息不会进入到运行阶段 能否在泛型里面使用具备继承关系的类？不可以 解决办法： 使用通配符 ?，但是会使得泛型的类型检查失去意义； 给泛型加入上边界 ? extends E； 给泛型加入下边界 ? super E； 泛型接口 泛型方法 123456789101112131415161718192021222324@Datapublic class GenericClassExample&lt;T&gt; { /** * member这个成员变量的类型为T,T的类型由外部指定 */ private T member; public GenericClassExample(T member) { this.member = member; } public static &lt;E&gt; void printArray(E[] inputArray) { for (E element : inputArray) { System.out.printf(\"%s\", element); System.out.printf(\" \"); } System.out.println(); } public T handleSomething(T target) { return target; }} 泛型方法中的泛型标识符可独立于泛型类存在的，而泛型类中其他方法受制于泛型标识符的 泛型字母的含义 E - Element 在集合中使用，因为集合中存放的是元素； T - Type Java类； K - Key 键； V - Value 值； N - Number 数值类型； Servlet原理总结 减少Servlet的数量 参照SpringMVC，仅通过DispatcherServlet进行请求派发； 拦截所有请求 解析请求 派发给对应的Controller里面的方法进行处理 简单工厂模式 定义一个工厂类，根据传入的参数值不同返回不同的实例 特点：被创建的实例具有共同的父类或接口 适用场景： 需要创建的对象较少； 客户端不关心对象的创建过程； 优点：可以对创建的对象进行“加工”，对客户端隐藏相关细节； 缺点：因创建逻辑复杂或创建对象过多而造成代码臃肿；新增、删除子类均会违反开闭原则； 开闭原则（待补全） 工厂方法模式 定义一个用于创建对象的接口，让子类决定实例化哪一个类 对类的实例化延迟到子类 优点： 遵循开闭原则 对客户端隐藏对象的创建细节 遵循单一职责 缺点： 增加子类的时候“拖家带口” 只支持同一类产品的创建 抽象工厂 提供一个创建一系列相关或相互依赖对象的接口 抽象工厂模式侧重的是同一产品族 工厂方法模式更加侧重于同一产品等级 解决了工厂模式只支持生产一种产品的弊端 新增一个产品族，只需要增加一个新的具体工厂，不需要修改代码； IOCSpring IOC容器使用了工厂模式+反射机制 反射：允许程序在运行时来进行自我检查并且对内部的成员进行操作 1）作用： 在运行时判断任意一个对象所属的类； 在运行时获取类的对象； 在运行时访问Java对象的属性、方法、构造方法等； 2）java.lang.reflect 类库里主要的类 Field：表示类中的成员变量 Method：表示类中的方法 Constructor：表示类的构造方法 Array：该类提供了动态创建数组和访问数组元素的静态方法 3）反射依赖的Class JVM中只有唯一一个和类相对应的Class对象来描述其类型信息。 4）获取Class对象的三种方式： Object -&gt; getClass() 任何数据类型（包括基本数据类型）都有一个“静态”的class属性 通过Class类的静态方法：forName(String className) （常用） 123456789101112131415public class ReflectTarget { public static void main(String[] args) throws ClassNotFoundException { ReflectTarget reflectTarget = new ReflectTarget(); // 第一种方式获取class对象 Class reflectTargetClass1 = reflectTarget.getClass(); // 第二种 Class reflectTargetClass2 = ReflectTarget.class; System.out.println(reflectTargetClass1 == reflectTargetClass2); // 第三种 Class reflectTargetClass3 = Class.forName(\"demo.reflect.ReflectTarget\"); System.out.println(reflectTargetClass2 == reflectTargetClass3); }} 5）获取并操作构造函数 1234567891011121314151617181920212223242526272829303132333435// 获取所有\"公有的\"的构造方法@CallerSensitivepublic Constructor&lt;?&gt;[] getConstructors() throws SecurityException { checkMemberAccess(Member.PUBLIC, Reflection.getCallerClass(), true); return copyConstructors(privateGetDeclaredConstructors(true));}// 获取所有的构造方法(包括private public default protected)@CallerSensitivepublic Constructor&lt;?&gt;[] getDeclaredConstructors() throws SecurityException { checkMemberAccess(Member.DECLARED, Reflection.getCallerClass(), true); return copyConstructors(privateGetDeclaredConstructors(false));}// 获取单个的\"公有的\"构造方法@CallerSensitivepublic Constructor&lt;T&gt; getConstructor(Class&lt;?&gt;... parameterTypes) throws NoSuchMethodException, SecurityException { checkMemberAccess(Member.PUBLIC, Reflection.getCallerClass(), true); return getConstructor0(parameterTypes, Member.PUBLIC);}// 获取某个构造方法(包括private public default protected)@CallerSensitivepublic Constructor&lt;T&gt; getDeclaredConstructor(Class&lt;?&gt;... parameterTypes) throws NoSuchMethodException, SecurityException { checkMemberAccess(Member.DECLARED, Reflection.getCallerClass(), true); return getConstructor0(parameterTypes, Member.DECLARED);}// 调用构造方法Constructor -&gt; newInstance(Object... initargs) // 暴力访问(忽略掉访问修饰符)Constructor -&gt; setAccessible(true) 6）获取并操作成员变量 12345678910111213141516171819202122232425262728293031323334353637383940// 获取所有的\"公有字段\" 包含继承字段@CallerSensitivepublic Field[] getFields() throws SecurityException { checkMemberAccess(Member.PUBLIC, Reflection.getCallerClass(), true); return copyFields(privateGetPublicFields(null));}// 获取所有字段(包括private修饰的) 不包含继承的字段@CallerSensitivepublic Field[] getDeclaredFields() throws SecurityException { checkMemberAccess(Member.DECLARED, Reflection.getCallerClass(), true); return copyFields(privateGetDeclaredFields(false));}// 获取某个\"公有的\"字段 包含继承字段@CallerSensitivepublic Field getField(String name) throws NoSuchFieldException, SecurityException { checkMemberAccess(Member.PUBLIC, Reflection.getCallerClass(), true); Field field = getField0(name); if (field == null) { throw new NoSuchFieldException(name); } return field;}// 获取某个字段(可以是私有的) 不包括继承字段@CallerSensitivepublic Field getDeclaredField(String name) throws NoSuchFieldException, SecurityException { checkMemberAccess(Member.DECLARED, Reflection.getCallerClass(), true); Field field = searchFields(privateGetDeclaredFields(false), name); if (field == null) { throw new NoSuchFieldException(name); } return field;}// 设置字段的值 obj:要设置的字段所在的对象 value:要为字段设置的值Field -&gt; public void set(Object obj, Object value); 7）获取并操作成员方法 1234567891011121314151617181920212223242526272829303132333435363738// 获取所有的\"公有方法\" 包含了父类的方法和Object类@CallerSensitivepublic Method[] getMethods() throws SecurityException { checkMemberAccess(Member.PUBLIC, Reflection.getCallerClass(), true); return copyMethods(privateGetPublicMethods());}// 获取所有的成员方法，包括私有的，不包含继承的@CallerSensitivepublic Method[] getDeclaredMethods() throws SecurityException { checkMemberAccess(Member.DECLARED, Reflection.getCallerClass(), true); return copyMethods(privateGetDeclaredMethods(false));}// name:方法名 Class...:形参的Class类型对象public Method getMethod(String name, Class&lt;?&gt;... parameterTypes) throws NoSuchMethodException, SecurityException { checkMemberAccess(Member.PUBLIC, Reflection.getCallerClass(), true); Method method = getMethod0(name, parameterTypes, true); if (method == null) { throw new NoSuchMethodException(getName() + \".\" + name + argumentTypesToString(parameterTypes)); } return method;}@CallerSensitivepublic Method getDeclaredMethod(String name, Class&lt;?&gt;... parameterTypes) throws NoSuchMethodException, SecurityException { checkMemberAccess(Member.DECLARED, Reflection.getCallerClass(), true); Method method = searchMethods(privateGetDeclaredMethods(false), name, parameterTypes); if (method == null) { throw new NoSuchMethodException(getName() + \".\" + name + argumentTypesToString(parameterTypes)); } return method;}// 调用方法 obj:要调用方法的对象 args:调用方法时传递的实参Method -&gt; public Object invoke(Object obj, Object... args); 8）反射的获取源 用XML来保存类相关的信息以供反射调用； 用注解来保存类相关的信息以供反射调用； 注解：提供一种为程序元素设置元数据的方法 元数据是添加到程序元素如方法、字段、类和包上的额外信息。 1）功能 作为特定的标记，用于告诉编译器一些信息； 编译时动态处理，如动态生成代码； 运行时动态处理，作为额外信息的载体，如获取注解信息； 2）注解分类 标准注解：Override、Deprecated、SuppressWarnings 元注解：@Retention、@Target、@Inherited、@Documented 自定义注解 3）元注解 ​ @Target：注解的作用目标 ​ @Retention：注解的生命周期 ​ @Documented：注解是否应当被包含在JavaDoc文档中 ​ @Inherited：是否允许子类继承该注解 单例模式（待总结） 使用反射时恶汉和懒汉模式都不能保证单例，所以采取枚举解决（枚举原理待补全） 需要实现的点 创建注解 提取标记对象 extractPackageClass 指定范围，获取范围内的所有类； 遍历所有类，获取被注解标记的类并加载进容器里； 实现容器 保存Class对象及其实例的载体 容器的加载（配置的管理与获取，获取指定范围内的Class对象，依据配置提取Class对象，连同实例一并存入容器） 容器的操作方式（涉及到容器的增删改查：增加、删除操作，根据Class获取对应实例，获取所有的Class和实例，通过注解来获取被注解标注的Class，通过超类获取对应的子类Class，获取容器载体保存Class的数量） 依赖注入 定义相关的注解标签 实现创建被注解标记的成员变量实例，并将其注入到成员变量里 依赖注入的使用 Spring框架有多种作用域 singleton prototype request session globalsession IOC源码学习 配置文件： 1）根据配置，生成用来描述bean的BeanDefinition，常用属性： 作用范围scope（@Scope） 懒加载lazy-init（@Lazy）：决定Bean实例是否延迟加载 首选primary（@Primary）：设置为true的bean会是优先的实现类 factory-bean和factory-method（@Configuration和@Bean） GenericBeanDefinition 2）术语补充 组件扫描：自动发现应用容器中需要创建的Bean 自动装配：自动满足Bean之间的依赖 3）ApplicationContext常用容器 传统的基于XML配置的经典容器 FileSystemXmlApplicationContext：从文件系统加载配置 ClassPathXmlApplicationContext：从classpath加载配置 XmlWebApplicationContext：用于Web应用程序的容器 refresh()主要功能： 容器初始化、配置解析 BeanFactoryPostProcessor和BeanPostProcessor的注册和激活 国际化配置 web内置容器的构造 模板方法模式： 复用代码，反向控制 Resource： 总结 1）容器初始化主要做的事情 场景问题 BeanFactory和factoryBean有什么联系和区别","link":"/2020/07/11/springframework/"},{"title":"logs","text":"Log4j.properties配置详解 Loggers组件这五个级别是有顺序的，DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL，分别用来指定这条日志信息的重要程度。 Log4j有一个规则：只输出级别不低于设定级别的日志信息，假设Loggers级别设定为INFO，则INFO、WARN、ERROR和FATAL级别的日志信息都会输出，而级别比INFO低的DEBUG则不会输出。 配置日志信息输出目的地（appender）1log4j.appender.appenderName = className appenderName：自定义appderName，在log4j.rootLogger设置中使用；className：可设值如下： (1) org.apache.log4j.ConsoleAppender（控制台）选项 Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。 ImmediateFlush=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。 Target=System.err：默认值是System.out。 (2) org.apache.log4j.FileAppender（文件）选项 Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。 ImmediateFlush=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。 Append=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。 File=D:/logs/logging.log4j：指定消息输出到logging.log4j文件中。 (3) org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件）选项 Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。 ImmediateFlush=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。 Append=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。 File=D:/logs/logging.log4j：指定当前消息输出到logging.log4j文件中。 DatePattern=’.’yyyy-MM：每月滚动一次日志文件，即每月产生一个新的日志文件。当前月的日志文件名为logging.log4j，前一个月的日志文件名为logging.log4j.yyyy-MM。 另外，也可以指定按周、天、时、分等来滚动日志文件，对应的格式如下： ‘.’yyyy-MM：每月 ‘.’yyyy-ww：每周 ‘.’yyyy-MM-dd：每天 ‘.’yyyy-MM-dd-a：每天两次 ‘.’yyyy-MM-dd-HH：每小时 ‘.’yyyy-MM-dd-HH-mm：每分钟 (4) org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件）选项 Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。 ImmediateFlush=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。 Append=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。 File=D:/logs/logging.log4j：指定消息输出到logging.log4j文件中。 MaxFileSize=100KB：后缀可以是KB, MB 或者GB。在日志文件到达该大小时，将会自动滚动，即将原来的内容移到logging.log4j.1文件中。 MaxBackupIndex=2：指定可以产生的滚动文件的最大数，例如，设为2则可以产生logging.log4j.1，logging.log4j.2两个滚动文件和一个logging.log4j文件。 （5）org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方） 配置日志信息的输出格式（Layout）1log4j.appender.appenderName.layout=className className：可设值如下： (1) org.apache.log4j.HTMLLayout（以HTML表格形式布局） LocationInfo=true：输出java文件名称和行号，默认值是false。 Title=My Logging： 默认值是Log4J Log Messages。 (2) org.apache.log4j.PatternLayout（可以灵活地指定布局模式） ConversionPattern=%m%n：设定以怎样的格式显示消息。 格式化符号说明： %p：输出日志信息的优先级，即DEBUG，INFO，WARN，ERROR，FATAL。 %d：输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，如：%d{yyyy/MM/dd HH:mm:ss,SSS}。 %r：输出自应用程序启动到输出该log信息耗费的毫秒数。 %t：输出产生该日志事件的线程名。 %l：输出日志事件的发生位置，相当于%c.%M(%F:%L)的组合，包括类全名、方法、文件名以及在代码中的行数。例如：test.TestLog4j.main(TestLog4j.java:10)。 %c：输出日志信息所属的类目，通常就是所在类的全名。 %M：输出产生日志信息的方法名。 %F：输出日志消息产生时所在的文件名称。 %L:：输出代码中的行号。 %m:：输出代码中指定的具体日志信息。 %n：输出一个回车换行符，Windows平台为”\\r\\n”，Unix平台为”\\n”。 %x：输出和当前线程相关联的NDC(嵌套诊断环境)，尤其用到像java servlets这样的多客户多线程的应用中。 %%：输出一个”%”字符。 另外，还可以在%与格式字符之间加上修饰符来控制其最小长度、最大长度、和文本的对齐方式。如： c：指定输出category的名称，最小的长度是20，如果category的名称长度小于20的话，默认的情况下右对齐。 %-20c：”-“号表示左对齐。 %.30c：指定输出category的名称，最大的长度是30，如果category的名称长度大于30的话，就会将左边多出的字符截掉，但小于30的话也不会补空格。 （3）org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串） （4）org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息）","link":"/2020/07/12/logs/"},{"title":"synchronized","text":"synchronizedJava多线程的锁都是基于对象的，Java中的每一个对象都可以作为一个锁。 还有一点需要注意的是，我们常听到的类锁其实也是对象锁。 Java类只有一个Class对象（可以有多个实例对象，多个实例共享这个Class对象），而Class对象也是特殊的Java对象。所以我们常说的类锁，其实就是Class对象的锁。 用法 1234567891011121314151617// 关键字在实例方法上，锁为当前实例public synchronized void instanceLock() { // code}// 关键字在静态方法上，锁为当前Class对象public static synchronized void classLock() { // code}// 关键字在代码块上，锁为括号里面的对象public void blockLock() { Object o = new Object(); synchronized (o) { // code }} 所谓“临界区”，指的是某一块代码区域，它同一时刻只能由一个线程执行。在上面的例子中，如果synchronized关键字在方法上，那临界区就是整个方法内部。而如果是使用synchronized代码块，那临界区就指的是代码块内部的区域。 12345678910111213141516171819202122232425// 等价情况1// 关键字在实例方法上，锁为当前实例public synchronized void instanceLock() { // code}// 关键字在代码块上，锁为括号里面的对象public void blockLock() { synchronized (this) { // code }}// 等价情况2// 关键字在静态方法上，锁为当前Class对象public static synchronized void classLock() { // code}// 关键字在代码块上，锁为括号里面的对象public void blockLock() { synchronized (this.getClass()) { // code }} 锁升级在Java 6 及其以后，一个对象其实有四种锁状态，它们级别由低到高依次是：无锁状态，偏向锁状态，轻量级锁状态，重量级锁状态。 一个对象的“锁”的信息存放在什么地方？ Java对象头 Mark Word的格式： 锁状态 29bit/61bit 1bit是否为偏向锁 2bit锁标志位 无锁 0 01 偏向锁 线程ID 1 01 轻量级锁 指向栈中锁记录的指针 此时这一位不用于标识偏向锁 00 重量级锁 指向互斥量（重量级锁）的指针 此时这一位不用于标识偏向锁 10 GC标记 此时这一位不用于标识偏向锁 11 当对象状态为偏向锁时，Mark Word存储的是偏向的线程ID；当状态为轻量级锁时，Mark Word存储的是指向线程栈中Lock Record的指针；当状态为重量级锁时，Mark Word为指向堆中的monitor对象的指针。 偏向锁Hotspot的作者经研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得，于是引入了偏向锁。 偏向锁会偏向于第一个访问锁的线程，如果在接下来的运行过程中，该锁没有被其他的线程访问，则持有偏向锁的线程将永远不需要触发同步。也就是说，偏向锁在资源无竞争情况下消除了同步语句，连CAS操作都不做了，提高了程序的运行性能。 实现原理 一个线程在第一次进入同步块时，会在对象头和栈帧中的锁记录里存储锁的偏向的线程ID。当下次该线程进入这个同步块时，会去检查锁的Mark Word里面是不是放的自己的线程ID。 如果是，表明该线程已经获得了锁，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁 ；如果不是，就代表有另一个线程来竞争这个偏向锁。这个时候会尝试使用CAS来替换Mark Word里面的线程ID为新线程的ID，这个时候要分两种情况： 成功，表示之前的线程不存在了， Mark Word里面的线程ID为新线程的ID，锁不会升级，仍然为偏向锁； 失败，表示之前的线程仍然存在，那么暂停之前的线程，设置偏向锁标识为0，并设置锁标志位为00，升级为轻量级锁，会按照轻量级锁的方式进行竞争锁。 撤销偏向锁 偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时， 持有偏向锁的线程才会释放锁。 偏向锁升级成轻量级锁时，会暂停拥有偏向锁的线程，重置偏向锁标识，大概过程如下： 在一个安全点（在这个时间点上没有字节码正在执行）停止拥有锁的线程； 遍历线程栈，如果存在锁记录的话，需要修复锁记录和Mark Word，使其变成无锁状态； 唤醒被停止的线程，将当前锁升级成轻量级锁； 所以，如果应用程序里所有的锁通常处于竞争状态，那么偏向锁就会是一种累赘，对于这种情况，我们可以一开始就把偏向锁这个默认功能给关闭： 1-XX:UseBiasedLocking=false 轻量级锁多个线程在不同时段获取同一把锁，即不存在锁竞争的情况，也就没有线程阻塞。针对这种情况，JVM采用轻量级锁来避免线程的阻塞与唤醒。 轻量级锁的加锁 JVM会为每个线程在当前线程的栈帧中创建用于存储锁记录的空间，Displaced Mark Word。如果一个线程获得锁时发现是轻量级锁，会把锁的Mark Word复制到自己的Displaced Mark Word里面。 然后线程尝试用CAS将锁的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示Mark Word已经被替换成了其他线程的锁记录，说明在与其它线程竞争锁，当前线程就尝试使用自旋来获取锁。 JDK采用适应性自旋，简单来说就是线程如果自旋成功了，则下次自旋的次数会更多，如果自旋失败了，则自旋的次数就会减少。 自旋也不是一直进行下去的，如果自旋到一定程度（和JVM、操作系统相关），依然没有获取到锁，称为自旋失败，那么这个线程会阻塞。同时这个锁就会升级成重量级锁。 轻量级锁的释放 在释放锁时，当前线程会使用CAS操作将Displaced Mark Word的内容复制回锁的Mark Word里面。如果没有发生竞争，那么这个复制的操作会成功。如果有其他线程因为自旋多次导致轻量级锁升级成了重量级锁，那么CAS操作会失败，此时会释放锁并唤醒被阻塞的线程。 重量级锁重量级锁依赖于操作系统的互斥量（mutex） 实现的，而操作系统中线程间状态的转换需要相对比较长的时间，所以重量级锁效率很低，但被阻塞的线程不会消耗CPU。 锁的升级流程每一个线程在准备获取共享资源时： 第一步，检查MarkWord里面是不是放的自己的ThreadId ,如果是，表示当前线程是处于 “偏向锁”； 第二步，如果MarkWord不是自己的ThreadId，锁升级，这时候，用CAS来执行切换，新的线程根据MarkWord里面现有的ThreadId，通知之前线程暂停，之前线程将Markword的内容置为空； 第三步，两个线程都把锁对象的HashCode复制到自己新建的用于存储锁的记录空间，接着开始通过CAS操作， 把锁对象的MarKword的内容修改为自己新建的记录空间的地址的方式竞争MarkWord； 第四步，第三步中成功执行CAS的获得资源，失败的则进入自旋； 第五步，自旋的线程在自旋过程中，成功获得资源(即之前获的资源的线程执行完成并释放了共享资源)，则整个状态依然处于 轻量级锁的状态，如果自旋失败； 第六步，进入重量级锁的状态，这个时候，自旋的线程进行阻塞，等待之前线程执行完成并唤醒自己； 各种锁的优缺点对比 锁 优点 缺点 适用场景 偏向锁 加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距。 如果线程间存在锁竞争，会带来额外的锁撤销的消耗。 适用于只有一个线程访问同步块场景。 轻量级锁 竞争的线程不会阻塞，提高了程序的响应速度。 如果始终得不到锁竞争的线程使用自旋会消耗CPU。 追求响应时间。同步块执行速度非常快。 重量级锁 线程竞争不使用自旋，不会消耗CPU。 线程阻塞，响应时间缓慢。 追求吞吐量。同步块执行时间较长。","link":"/2020/07/14/synchronized/"},{"title":"volatile","text":"volatileJMMJMM的抽象：主内存和本地内存 JMM有以下规定： ​ 所有变量都存储在主内存中，同时每个线程也有自己独立的工作内存，工作内存中的变量内容是主内存中的拷贝； ​ 线程不能直接读写主内存中的变量，而是只操作自己工作内存中的变量，然后再同步到主内存中； ​ 主内存是多个线程共享的，但线程间不共享工作内存，如果线程间需要通信，必须借助主内存中转来完成； 为什么会有可见性问题 CPU有多级缓存，导致读的数据过期； 高速缓存的容量比主内存小，但是速度仅次于寄存器，所以在CPU和主内存之间就多了Cache层； 线程间的对于共享变量的可见性问题不是直接由多核引起的，而是由多缓存引起的； 如果所有核心都只用一个缓存，那么就不存在内存可见性问题了； 每个核心都会将自己需要的数据读到独占缓存中，数据修改后也是写入到缓存中，然后等待刷入主存中。所以会导致有些核心取到的值是一个过期的值； 重排序与happens-before 为什么存在重排序？为什么可以提高性能？ 12a = b + cd = e - f 先加载b、c（注意，即有可能先加载b，也有可能先加载c），但是在执行add(b,c)的时候，需要等待b、c装载结束才能继续执行，也就是增加了停顿，那么后面的指令也会依次有停顿,这降低了计算机的执行效率。 为了减少这个停顿，我们可以先加载e和f,然后再去加载add(b,c),这样做对程序（串行）是没有影响的,但却减少了停顿。既然add(b,c)需要停顿，那还不如去做一些有意义的事情。 指令重排对于提高CPU处理性能十分必要。虽然由此带来了乱序的问题，但是这点牺牲是值得的。 指令重排的类型 编译器优化重排：编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序； 指令并行重排：现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性(即后一个执行的语句无需依赖前面执行的语句的结果)，处理器可以改变语句对应的机器指令的执行顺序； 内存系统重排：由于处理器使用缓存和读写缓存冲区，这使得加载(load)和存储(store)操作看上去可能是在乱序执行，因为三级缓存的存在，导致内存与缓存的数据同步存在时间差； happens-before happens-before原则 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前； 两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么JMM也允许这样的重排序； 天然的happens-before关系 程序顺序规则：一个线程中的每一个操作，happens-before于该线程中的任意后续操作； 监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁； volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读； 传递性：如果A happens-before B，且B happens-before C，那么A happens-before C； start规则：如果线程A执行操作ThreadB.start()启动线程B，那么A线程的ThreadB.start（）操作happens-before于线程B中的任意操作； join规则：如果线程A执行操作ThreadB.join（）并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回； volatile 两个作用 保证变量的内存可见性； 禁止volatile变量与普通变量重排序（JSR133提出，Java 5 开始才有这个“增强的volatile内存语义”）； 原理 1）可见性实现： 修改volatile变量时会强制将修改后的值刷新的主内存中； 修改volatile变量后会导致其他线程工作内存中对应的变量值失效。因此，再读取该变量值的时候就需要重新从读取主内存中的值； 2）禁止重排序实现： JVM限制处理器的重排序 —— 内存屏障 硬件层面，内存屏障分两种：读屏障（Load Barrier）和写屏障（Store Barrier）。 内存屏障有两个作用： 阻止屏障两侧的指令重排序；强制把写缓冲区/高速缓存中的脏数据等写回主内存，或者让缓存中相应的数据失效；（注意这里的缓存主要指的是CPU缓存，如L1，L2等） 编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。编译器选择了一个比较保守的JMM内存屏障插入策略，这样可以保证在任何处理器平台，任何程序中都能得到正确的volatile内存语义。这个策略是： 在每个volatile写操作前插入一个StoreStore屏障； 在每个volatile写操作后插入一个StoreLoad屏障； 在每个volatile读操作后插入一个LoadLoad屏障； 在每个volatile读操作后再插入一个LoadStore屏障； 再介绍一下volatile与普通变量的重排序规则: 如果第一个操作是volatile读，那无论第二个操作是什么，都不能重排序； 如果第二个操作是volatile写，那无论第一个操作是什么，都不能重排序； 如果第一个操作是volatile写，第二个操作是volatile读，那不能重排序； 应用 1）单例模式 —— 双重锁检查 12345678910111213141516171819public class Singleton { private volatile static Singleton instance; private Singleton() { } public static Singleton getInstance() { if (instance == null) { synchronized (Singleton.class) { if (instance == null) { instance = new Singleton(); } } } return instance; }} 如果这里的变量声明不使用volatile关键字，则可能会发生错误的。它可能会被重排序： instance = new Singleton(); 123456789// 可以分解为以下三个步骤1 memory=allocate();// 分配内存 相当于c的malloc2 ctorInstanc(memory) //初始化对象3 s=memory //设置s指向刚分配的地址// 上述三个步骤可能会被重排序为 1-3-2，也就是：1 memory=allocate();// 分配内存 相当于c的malloc3 s=memory //设置s指向刚分配的地址2 ctorInstanc(memory) //初始化对象 而一旦假设发生了这样的重排序，比如线程A执行了步骤1和步骤3，但是步骤2还没有执行完。这个时候另一个线程B执行到了if (instance == null)，它会判定instance不为空，然后直接返回了一个未初始化完成的instance！","link":"/2020/07/13/volatile/"}],"tags":[{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"concurrent","slug":"concurrent","link":"/tags/concurrent/"},{"name":"Distribution","slug":"Distribution","link":"/tags/Distribution/"},{"name":"Dubbo","slug":"Dubbo","link":"/tags/Dubbo/"},{"name":"lc","slug":"lc","link":"/tags/lc/"},{"name":"lcof","slug":"lcof","link":"/tags/lcof/"},{"name":"dp","slug":"dp","link":"/tags/dp/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"}],"categories":[{"name":"剑指offer","slug":"剑指offer","link":"/categories/%E5%89%91%E6%8C%87offer/"}]}